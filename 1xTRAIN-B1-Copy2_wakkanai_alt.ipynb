{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import os\n",
    "from os.path import dirname, abspath, join\n",
    "from os import getcwd\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import string\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import socket\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed_arg = int(sys.argv[1])\n",
    "# print (\"\\n\\nSeed ARG: \",seed_arg)\n",
    "seed_arg = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "seedlist = np.array([161, 314, 228, 271828, 230, 4271031, 5526538, 6610165, 9849252, 34534, 73422, 8765])\n",
    "seed = seedlist[seed_arg]\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MODEL :  B1_2_wakkanai_alt\n",
      "SEED  :  1\n",
      "HOST  :  e5155838fc98\n",
      "START :  2019-03-17 21:31:51.487943\n"
     ]
    }
   ],
   "source": [
    "NAME       = 'B1_2_wakkanai_alt'\n",
    "MODELNAME  = NAME + '_' + str(seed) + '.pt'\n",
    "print(\"\\nMODEL : \", NAME)\n",
    "print(\"SEED  : \",seed_arg)\n",
    "print(\"HOST  : \",socket.gethostname())\n",
    "print(\"START : \",datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ENO(object):\n",
    "    \n",
    "    #no. of forecast types is 6 ranging from 0 to 5\n",
    "  \n",
    "    def __init__(self, location='tokyo', year=2010, shuffle=False, day_balance=False):\n",
    "        self.location = location\n",
    "        self.year = year\n",
    "        self.day = None\n",
    "        self.hr = None\n",
    "        \n",
    "        self.shuffle = shuffle\n",
    "        self.day_balance = day_balance\n",
    "\n",
    "        self.TIME_STEPS = None #no. of time steps in one episode\n",
    "        self.NO_OF_DAYS = None #no. of days in one year\n",
    "        \n",
    "        self.NO_OF_DAYTYPE = 10 #no. of daytypes\n",
    "        self.daycounter = 0 #to count number of days that have been passed\n",
    "        \n",
    "        self.sradiation = None #matrix with GSR for the entire year\n",
    "        self.senergy = None #matrix with harvested energy data for the entire year\n",
    "        self.fforecast = None #array with forecast values for each day\n",
    "        \n",
    "\n",
    "        self.henergy = None #harvested energy variable\n",
    "        self.fcast = None #forecast variable\n",
    "        self.sorted_days = [] #days sorted according to day type\n",
    "        \n",
    "        self.SMAX = 1000 # 1 Watt Solar Panel\n",
    "\n",
    "    \n",
    "    #function to get the solar data for the given location and year and prep it\n",
    "    def get_data(self):\n",
    "        #solar_data/CSV files contain the values of GSR (Global Solar Radiation in MegaJoules per meters squared per hour)\n",
    "        #weather_data/CSV files contain the weather summary from 06:00 to 18:00 and 18:00 to 06:00+1\n",
    "        location = self.location\n",
    "        year = self.year\n",
    "\n",
    "        THIS_DIR = getcwd()\n",
    "        SDATA_DIR = abspath(join(THIS_DIR, 'solar_data'))  #abspath(join(THIS_DIR, '../../..', 'data'))\n",
    "        \n",
    "        sfile = SDATA_DIR + '/' + location +'/' + str(year) + '.csv'\n",
    "        \n",
    "        #skiprows=4 to remove unnecessary title texts\n",
    "        #usecols=4 to read only the Global Solar Radiation (GSR) values\n",
    "        solar_radiation = pd.read_csv(sfile, skiprows=4, encoding='shift_jisx0213', usecols=[4])\n",
    "      \n",
    "        #convert dataframe to numpy array\n",
    "        solar_radiation = solar_radiation.values\n",
    "\n",
    "        #convert missing data in CSV files to zero\n",
    "        solar_radiation[np.isnan(solar_radiation)] = 0\n",
    "\n",
    "        #reshape solar_radiation into no_of_daysx24 array\n",
    "        solar_radiation = solar_radiation.reshape(-1,24)\n",
    "\n",
    "        if(self.shuffle): #if class instatiation calls for shuffling the day order. Required when learning\n",
    "            np.random.shuffle(solar_radiation) \n",
    "        self.sradiation = solar_radiation\n",
    "        \n",
    "        #GSR values (in MJ/sq.mts per hour) need to be expressed in mW\n",
    "        # Conversion is accomplished by \n",
    "        # solar_energy = GSR(in MJ/m2/hr) * 1e6 * size of solar cell * efficiency of solar cell /(60x60) *1000 (to express in mW)\n",
    "        # the factor of 2 in the end is assuming two solar cells\n",
    "        self.senergy = 2*self.sradiation * 1e6 * (55e-3 * 70e-3) * 0.15 * 1000/(60*60)\n",
    "\n",
    "        return 0\n",
    "    \n",
    "    #function to map total day radiation into type of day ranging from 0 to 5\n",
    "    #the classification into day types is quite arbitrary. There is no solid logic behind this type of classification.\n",
    "    \n",
    "    def get_day_state(self,tot_day_radiation):\n",
    "        bin_edges = np.array([0, 3.5, 6.5, 9.0, 12.5, 15.5, 18.5, 22.0, 25, 28])\n",
    "        for k in np.arange(1,bin_edges.size):\n",
    "            if (bin_edges[k-1] < tot_day_radiation <= bin_edges[k]):\n",
    "                day_state = k -1\n",
    "            else:\n",
    "                day_state = bin_edges.size - 1\n",
    "        return int(day_state)\n",
    "    \n",
    "    def get_forecast(self):\n",
    "        #create a perfect forecaster.\n",
    "        tot_day_radiation = np.sum(self.sradiation, axis=1) #contains total solar radiation for each day\n",
    "        get_day_state = np.vectorize(self.get_day_state)\n",
    "        self.fforecast = get_day_state(tot_day_radiation)\n",
    "        \n",
    "        #sort days depending on the type of day and shuffle them; maybe required when learning\n",
    "        for fcast in range(0,6):\n",
    "            fcast_days = ([i for i,x in enumerate(self.fforecast) if x == fcast])\n",
    "            np.random.shuffle(fcast_days)\n",
    "            self.sorted_days.append(fcast_days)\n",
    "        return 0\n",
    "    \n",
    "    def reset(self,day=0): #it is possible to reset to the beginning of a certain day\n",
    "        \n",
    "        self.get_data() #first get data for the given year\n",
    "        self.get_forecast() #calculate the forecast\n",
    "        \n",
    "        self.TIME_STEPS = self.senergy.shape[1]\n",
    "        self.NO_OF_DAYS = self.senergy.shape[0]\n",
    "        \n",
    "        self.day = day\n",
    "        self.hr = 0\n",
    "        \n",
    "        self.henergy = self.senergy[self.day][self.hr]\n",
    "        self.fcast = self.fforecast[self.day]\n",
    "        \n",
    "        end_of_day = False\n",
    "        end_of_year = False\n",
    "        return [self.henergy, self.fcast, end_of_day, end_of_year]\n",
    "\n",
    "    \n",
    "    def step(self):\n",
    "        end_of_day = False\n",
    "        end_of_year = False\n",
    "        if not(self.day_balance): #if daytype balance is not required\n",
    "            if(self.hr < self.TIME_STEPS - 1):\n",
    "                self.hr += 1\n",
    "                self.henergy = self.senergy[self.day][self.hr] \n",
    "                self.fcast = self.fforecast[self.day]\n",
    "            else:\n",
    "                if(self.day < self.NO_OF_DAYS -1):\n",
    "                    end_of_day = True\n",
    "                    self.hr = 0\n",
    "                    self.day += 1\n",
    "                    self.henergy = self.senergy[self.day][self.hr] \n",
    "                    self.fcast = self.fforecast[self.day]\n",
    "                else:\n",
    "                    end_of_day = True\n",
    "                    end_of_year = True\n",
    "                    \n",
    "        else: #when training, we want all daytypes to be equally represented for robust policy\n",
    "              #obviously, the days are going to be in random order\n",
    "            if(self.hr < self.TIME_STEPS - 1):\n",
    "                self.hr += 1\n",
    "                self.henergy = self.senergy[self.day][self.hr]\n",
    "                self.fcast = self.fforecast[self.day]\n",
    "            else:\n",
    "                if(self.daycounter < self.NO_OF_DAYS -1):\n",
    "                    end_of_day = True\n",
    "                    self.daycounter += 1\n",
    "                    self.hr = 0\n",
    "                    daytype = random.choice(np.arange(0,self.NO_OF_DAYTYPE)) #choose random daytype\n",
    "                    self.day = np.random.choice(self.sorted_days[daytype]) #choose random day from that daytype\n",
    "                    self.henergy = self.senergy[self.day][self.hr] \n",
    "                    self.fcast = self.fforecast[self.day]\n",
    "                else: \n",
    "                    end_of_day = True\n",
    "                    end_of_year = True\n",
    "                    self.daycounter = 0\n",
    "        \n",
    "        \n",
    "        return [self.henergy, self.fcast, end_of_day, end_of_year]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CAPM (object):\n",
    "    def __init__(self,location='tokyo', year=2010, shuffle=False, trainmode=False):\n",
    "\n",
    "        #all energy values i.e. BMIN, BMAX, BOPT, HMAX are in mWhr. Assuming one timestep is one hour\n",
    "        \n",
    "        self.BMIN = 0.0                #Minimum battery level that is tolerated. Maybe non-zero also\n",
    "        self.BMAX = 10000.0            #Max Battery Level. May not necessarily be equal to total batter capacity [3.6V x 2500mAh]\n",
    "        self.BOPT = 0.5 * self.BMAX    #Optimal Battery Level. Assuming 50% of battery is the optimum\n",
    "        self.BLIM_LO = 0.15*self.BMAX\n",
    "        self.BLIM_HI = 0.95*self.BMAX\n",
    "        self.BSAFE_LO = 0.35*self.BMAX\n",
    "        self.BSAFE_HI = 0.65*self.BMAX\n",
    "        \n",
    "        self.ENP_MARGIN = 0.3*self.BMAX\n",
    "\n",
    "        \n",
    "        self.HMIN = 0      #Minimum energy that can be harvested by the solar panel.\n",
    "        self.HMAX = None   #Maximum energy that can be harvested by the solar panel. [500mW]\n",
    "        \n",
    "        self.DMAX = 500      #Maximum energy that can be consumed by the node in one time step. [~ 3.6V x 135mA]\n",
    "        self.N_ACTIONS = 10  #No. of different duty cycles possible\n",
    "        self.DMIN = self.DMAX/self.N_ACTIONS #Minimum energy that can be consumed by the node in one time step. [~ 3.6V x 15mA]\n",
    "        \n",
    "        self.binit = None     #battery at the beginning of day\n",
    "        self.btrack = []      #track the mean battery level for each day\n",
    "        self.atrack = []      #track the duty cycles for each day\n",
    "        self.htrack = []      #track the harvested for each day\n",
    "        self.batt = None      #battery variable\n",
    "        self.enp = None       #enp at end of hr\n",
    "        self.henergy = None   #harvested energy variable\n",
    "        self.fcast = None     #forecast variable\n",
    "        \n",
    "        self.MUBATT = 0.6\n",
    "        self.SDBATT = 0.02\n",
    "        \n",
    "        self.MUHENERGY = 0.5\n",
    "        self.SDHENERGY = 0.2\n",
    "        \n",
    "        self.MUENP = 0\n",
    "        self.SDENP = 0.02\n",
    "        \n",
    "        self.location  = location\n",
    "        self.year      = year\n",
    "        self.shuffle   = shuffle\n",
    "        self.trainmode = trainmode\n",
    "        self.eno       = None\n",
    "        \n",
    "        self.day_violation_flag = False\n",
    "        self.violation_flag     = False\n",
    "        self.violation_counter  = 0\n",
    "        \n",
    "        self.batt_violations    = 0\n",
    "\n",
    "        self.NO_OF_DAYTYPE      = 10 #no. of daytypes\n",
    " \n",
    "    def reset(self,day=0,batt=-1):\n",
    "        henergy, fcast, day_end, year_end = self.eno.reset(day) #reset the eno environment\n",
    "        self.violation_flag = False\n",
    "        self.violation_counter = 0\n",
    "        self.batt_violations = 0\n",
    "        \n",
    "        if(batt == -1):\n",
    "            self.batt = self.BOPT\n",
    "        else:\n",
    "            self.batt = batt\n",
    "            \n",
    "        self.batt = np.clip(self.batt, self.BMIN, self.BMAX)\n",
    "        self.binit = self.batt\n",
    "        self.btrack = np.append(self.btrack, self.batt) #track battery levels\n",
    "\n",
    "        self.enp = self.BOPT - self.batt\n",
    "#         self.enp = self.binit - self.batt #enp is calculated\n",
    "        self.henergy = np.clip(henergy, self.HMIN, self.HMAX) #clip henergy within HMIN and HMAX\n",
    "        self.fcast = fcast\n",
    "        \n",
    "        norm_batt    = self.batt    /self.BMAX\n",
    "        norm_enp     = self.enp     /self.BMAX\n",
    "        norm_henergy = self.henergy /self.HMAX\n",
    "        norm_fcast   = self.fcast   /(self.NO_OF_DAYTYPE-1)\n",
    "        c_state = [norm_batt, norm_enp, norm_henergy, norm_fcast] #continuous states\n",
    "\n",
    "        reward = 0\n",
    "        \n",
    "        return [c_state, reward, day_end, year_end]\n",
    "    \n",
    "    def getstate(self): #query the present state of the system\n",
    "        norm_batt    = self.batt    /self.BMAX\n",
    "        norm_enp     = self.enp     /self.BMAX\n",
    "        norm_henergy = self.henergy /self.HMAX\n",
    "        norm_fcast   = self.fcast   /(self.NO_OF_DAYTYPE-1)\n",
    "        c_state = [norm_batt, norm_enp, norm_henergy, norm_fcast] #continuous states\n",
    "\n",
    "        return c_state\n",
    "        \n",
    "    \n",
    "    #reward function\n",
    "    def rewardfn(self):\n",
    "        violation_penalty = 0\n",
    "        bmean = self.btrack.mean()\n",
    "        bdev = self.BOPT - bmean\n",
    "        if np.abs(bdev) > (self.BOPT - self.BLIM_LO):\n",
    "            reward = 2-np.abs(bdev)/self.BMAX*10\n",
    "        else:\n",
    "            reward = 2\n",
    "#         reward = 2 - 20*np.abs(bdev)/self.BMAX\n",
    "        if(self.day_violation_flag):\n",
    "            violation_penalty += 3    #penalty for violating battery limits anytime during the day\n",
    "        return (reward - violation_penalty)\n",
    "    \n",
    "    \n",
    "    \n",
    "    def step(self, action):\n",
    "        day_end = False\n",
    "        year_end = False\n",
    "        self.violation_flag = False\n",
    "        reward = 0\n",
    "        self.atrack = np.append(self.atrack, action+1) #track duty cycles\n",
    "        self.htrack = np.append(self.htrack, self.henergy)\n",
    "\n",
    "#         action_var = np.abs(np.mean(self.atrack) - action)/9 #can vary from 0 to 1\n",
    "#         reward += 0.25*(0.5 - action_var ) #reward penalizing high duty cycle variance [-0.5 to 0.5]*0.25\n",
    "      \n",
    "        action = np.clip(action, 0, self.N_ACTIONS-1) #action values range from (0 to N_ACTIONS-1)\n",
    "        e_consumed = (action+1)*self.DMAX/self.N_ACTIONS   #energy consumed by the node\n",
    "        \n",
    "        \n",
    "        self.batt += (self.henergy - e_consumed)\n",
    "        if(self.batt <= self.BMIN or self.batt >= self.BMAX ):\n",
    "                self.batt_violations += 1\n",
    "        \n",
    "        if(self.batt < self.BLIM_LO or self.batt > self.BLIM_HI ):\n",
    "            self.violation_flag = True #penalty for violating battery limits everytime it happens\n",
    "#             reward -= 2\n",
    "#             if(self.batt < self.BLIM_LO): #battery depletion is more fatal than battery overflow\n",
    "#                 reward -= 2\n",
    "\n",
    "        if(self.violation_flag):\n",
    "            if(self.day_violation_flag == False): #penalty for violating battery limits anytime during the day - triggers once everyday\n",
    "                self.violation_counter += 1\n",
    "                self.day_violation_flag = True\n",
    "                \n",
    "        #calculate ENP before clipping\n",
    "        self.enp = self.BOPT - self.batt\n",
    "        \n",
    "        self.batt = np.clip(self.batt, self.BMIN, self.BMAX) #clip battery values within permitted level\n",
    "        self.btrack = np.append(self.btrack, self.batt) #track battery levels\n",
    "        \n",
    "        \n",
    "        #proceed to the next time step\n",
    "       \n",
    "        self.henergy, self.fcast, day_end, year_end = self.eno.step()\n",
    "        self.henergy = np.clip(self.henergy, self.HMIN, self.HMAX) #clip henergy within HMIN and HMAX\n",
    "                        \n",
    "        if(day_end): #if eno object flags that the day has ended then give reward\n",
    "            reward += self.rewardfn()\n",
    "            if (self.trainmode): #reset battery to optimal level if limits are exceeded when training\n",
    "#                 self.batt = np.random.uniform(self.DMAX*self.eno.TIME_STEPS/self.BMAX,0.8)*self.BMAX\n",
    "#                 if (self.violation_flag):\n",
    "                if np.random.uniform() < HELP : #occasionaly reset the battery\n",
    "                    self.batt = self.BOPT  \n",
    "            \n",
    "            self.day_violation_flag = False\n",
    "            self.binit = self.batt #this will be the new initial battery level for next day\n",
    "            self.btrack = [] #clear battery tracker\n",
    "            self.atrack = [] #clear duty cycle tracker\n",
    "            self.htrack = [] #clear henergy tracker\n",
    "   \n",
    "        norm_batt    = self.batt    /self.BMAX\n",
    "        norm_enp     = self.enp     /self.BMAX\n",
    "        norm_henergy = self.henergy /self.HMAX\n",
    "        norm_fcast   = self.fcast   /(self.NO_OF_DAYTYPE-1)\n",
    "        c_state = [norm_batt, norm_enp, norm_henergy, norm_fcast] #continuous states\n",
    "        \n",
    "        return [c_state, reward, day_end, year_end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper Parameters\n",
    "BATCH_SIZE          = 12\n",
    "WT_DECAY            = None\n",
    "LR                  = 1e-4          # learning rate\n",
    "EPSILON             = 0.9           # greedy policy\n",
    "GAMMA               = 0.9           # reward discount\n",
    "LAMBDA              = 0.95          # parameter decay\n",
    "TARGET_REPLACE_ITER = 24*7*4*18     # target update frequency\n",
    "MEMORY_CAPACITY     = 24*7*4*12*3   # store upto six month worth of memory   \n",
    "\n",
    "N_ACTIONS           = 10            # no. of duty cycles (0,1,2,3,4)\n",
    "N_STATES            = 4             # number of state space parameter [batt, enp, henergy, fcast]\n",
    "\n",
    "HIDDEN_LAYER        = 50            # width of NN\n",
    "NO_OF_ITERATIONS    = 100\n",
    "GPU                 = False         # device\n",
    "HELP                = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "#Class definitions for NN model and learning algorithm\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(N_STATES, HIDDEN_LAYER)\n",
    "        nn.init.kaiming_uniform_(self.fc1.weight)\n",
    "        \n",
    "#         self.fc2 = nn.Linear(HIDDEN_LAYER, HIDDEN_LAYER)\n",
    "#         nn.init.kaiming_uniform_(self.fc2.weight)\n",
    "        \n",
    "#         self.fc3 = nn.Linear(HIDDEN_LAYER, HIDDEN_LAYER)\n",
    "#         nn.init.kaiming_uniform_(self.fc3.weight)\n",
    "\n",
    "        self.fc_out = nn.Linear(HIDDEN_LAYER, N_ACTIONS)\n",
    "        nn.init.xavier_uniform_(self.fc_out.weight) \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "#         x = F.leaky_relu(x)\n",
    "#         x = self.fc2(x)\n",
    "#         x = F.relu(x)\n",
    "#         x = self.fc3(x)\n",
    "#         x = F.relu(x)\n",
    "        x = self.fc_out(x)\n",
    "        return x\n",
    "    \n",
    "class DQN(object):\n",
    "    def __init__(self):\n",
    "        if(GPU): \n",
    "            device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        else:\n",
    "            device = torch.device('cpu')\n",
    "        self.eval_net, self.target_net = Net(), Net()\n",
    "        self.eval_net.to(device)\n",
    "        self.target_net.to(device)\n",
    "        self.device = device\n",
    "#         print(\"Neural net\")\n",
    "#         print(self.eval_net)\n",
    "        self.learn_step_counter = 0                                     # for target updating\n",
    "        self.good_memory_counter = 0                                         # for storing memory\n",
    "        self.good_memory = np.zeros((MEMORY_CAPACITY, N_STATES * 2 + 2))     # initialize memory [mem: ([s], a, r, [s_]) ]\n",
    "        \n",
    "        self.bad_memory_counter = 0                                         # for storing memory\n",
    "        self.bad_memory = np.zeros((MEMORY_CAPACITY, N_STATES * 2 + 2))     # initialize memory [mem: ([s], a, r, [s_]) ]\n",
    "        \n",
    "        \n",
    "        self.optimizer = torch.optim.Adam(self.eval_net.parameters(), lr=LR)\n",
    "#         self.optimizer = torch.optim.Adam(self.eval_net.parameters(), lr=LR, weight_decay=WT_DECAY)\n",
    "#         self.loss_func = nn.SmoothL1Loss()\n",
    "        self.loss_func = nn.MSELoss()\n",
    "        self.nettoggle = False\n",
    "\n",
    "    def choose_action(self, x):\n",
    "        x = torch.unsqueeze(torch.FloatTensor(x), 0)\n",
    "        x = x.to(self.device)\n",
    "\n",
    "        actions_value = self.eval_net.forward(x)\n",
    "        actions_value = actions_value.to(torch.device(\"cpu\"))\n",
    "        action = torch.max(actions_value, 1)[1].data.numpy()\n",
    "        action = action[0] # return the argmax index\n",
    "        if np.random.uniform() > EPSILON:   # greedy\n",
    "            action += np.random.randint(-3, 3)\n",
    "            action = int(np.clip(action, 0, N_ACTIONS-1))\n",
    "        return action\n",
    "    \n",
    "    def choose_greedy_action(self, x):\n",
    "        x = torch.unsqueeze(torch.FloatTensor(x), 0)\n",
    "        x = x.to(self.device)\n",
    "\n",
    "        # input only one sample\n",
    "        if True:   # greedy\n",
    "            actions_value = self.eval_net.forward(x)\n",
    "            actions_value = actions_value.to(torch.device(\"cpu\"))\n",
    "            action = torch.max(actions_value, 1)[1].data.numpy()\n",
    "            action = action[0] # return the argmax index\n",
    "        return action\n",
    "\n",
    "    def store_transition(self, s, a, r, s_):\n",
    "        transition = np.hstack((s, [a, r], s_))\n",
    "        # replace the old memory with new memory\n",
    "        index = self.memory_counter % MEMORY_CAPACITY\n",
    "        self.memory[index, :] = transition\n",
    "        self.memory_counter += 1\n",
    "    \n",
    "    def store_day_transition(self, transition):\n",
    "      \n",
    "        if(transition[-1][5] < 0):\n",
    "            index = self.bad_memory_counter % MEMORY_CAPACITY\n",
    "            self.bad_memory= np.insert(self.bad_memory, index, transition,0)\n",
    "            self.bad_memory_counter += transition.shape[0]\n",
    "            self.bad_memory=self.bad_memory[:int(MEMORY_CAPACITY)]\n",
    "        \n",
    "        else:\n",
    "            index = self.good_memory_counter % MEMORY_CAPACITY\n",
    "            self.good_memory= np.insert(self.good_memory, index, transition,0)\n",
    "            self.good_memory_counter += transition.shape[0]\n",
    "            self.good_memory=self.good_memory[:int(MEMORY_CAPACITY)]\n",
    "\n",
    "    def learn(self):\n",
    "        # target parameter update\n",
    "        if self.learn_step_counter % TARGET_REPLACE_ITER == 0:\n",
    "            self.target_net.load_state_dict(self.eval_net.state_dict())\n",
    "            self.nettoggle = not self.nettoggle\n",
    "        self.learn_step_counter += 1\n",
    "\n",
    "        # sample batch transitions\n",
    "        good_sample_index = np.random.choice(int(MEMORY_CAPACITY), int(0.5*BATCH_SIZE))\n",
    "        bad_sample_index  = np.random.choice(int(MEMORY_CAPACITY), BATCH_SIZE - int(BATCH_SIZE*0.50))\n",
    "\n",
    "        b_good_memory = self.good_memory[good_sample_index, :]\n",
    "        b_bad_memory = self.bad_memory[bad_sample_index, :]\n",
    "        b_memory = np.vstack((b_good_memory,b_bad_memory))\n",
    "\n",
    "        b_s = torch.FloatTensor(b_memory[:, :N_STATES])\n",
    "        b_a = torch.LongTensor(b_memory[:, N_STATES:N_STATES+1].astype(int))\n",
    "        b_r = torch.FloatTensor(b_memory[:, N_STATES+1:N_STATES+2])\n",
    "        b_s_ = torch.FloatTensor(b_memory[:, -N_STATES:])\n",
    "        \n",
    "        b_s = b_s.to(self.device)\n",
    "        b_a = b_a.to(self.device)\n",
    "        b_r = b_r.to(self.device)\n",
    "        b_s_ = b_s_.to(self.device)\n",
    "\n",
    "        # q_eval w.r.t the action in experience\n",
    "        q_eval = self.eval_net(b_s).gather(1, b_a)  # shape (batch, 1)\n",
    "        q_next = self.target_net(b_s_).detach()     # detach from graph, don't backpropagate\n",
    "        q_target = b_r + GAMMA * q_next.max(1)[0].view(BATCH_SIZE, 1)   # shape (batch, 1)\n",
    "        loss = self.loss_func(q_eval, q_target)\n",
    "\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stdize(s):\n",
    "    MU_BATT = 0.5\n",
    "    SD_BATT = 0.15\n",
    "    \n",
    "    MU_ENP = 0\n",
    "    SD_ENP = 0.15\n",
    "    \n",
    "    MU_HENERGY = 0.35\n",
    "    SD_HENERGY = 0.25\n",
    "    \n",
    "    MU_FCAST = 0.42\n",
    "    SD_FCAST = 0.27\n",
    "    \n",
    "    norm_batt, norm_enp, norm_henergy, norm_fcast = s\n",
    "    \n",
    "    std_batt    = (norm_batt    - MU_BATT    )/SD_BATT\n",
    "    std_enp     = (norm_enp     - MU_ENP     )/SD_ENP\n",
    "    std_henergy = (norm_henergy - MU_HENERGY )/SD_HENERGY\n",
    "    std_fcast   = (norm_fcast   - MU_FCAST   )/SD_FCAST\n",
    "\n",
    "    return [std_batt, std_enp, std_henergy, std_fcast]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BMIN       =  0.0\n",
      "BMAX       =  10000.0\n",
      "BOPT       =  5000.0\n",
      "BLIM_LO    =  1500.0\n",
      "BLIM_HI    =  9500.0\n",
      "BSAFE_LO   =  3500.0\n",
      "BSAFE_HI   =  6500.0\n",
      "ENP_MARGIN =  3000.0\n"
     ]
    }
   ],
   "source": [
    "#CONSTANTS\n",
    "LOCATION = 'tokyo'\n",
    "YEAR = 2010\n",
    "capm      = CAPM(LOCATION,YEAR,shuffle=False, trainmode=False) #instantiate the CAPM class\n",
    "print(\"BMIN       = \", capm.BMIN)\n",
    "print(\"BMAX       = \", capm.BMAX)\n",
    "print(\"BOPT       = \", capm.BOPT)\n",
    "print(\"BLIM_LO    = \", capm.BLIM_LO)\n",
    "print(\"BLIM_HI    = \", capm.BLIM_HI)\n",
    "print(\"BSAFE_LO   = \", capm.BSAFE_LO)\n",
    "print(\"BSAFE_HI   = \", capm.BSAFE_HI)\n",
    "print(\"ENP_MARGIN = \", capm.ENP_MARGIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF_1c(0)            =  -3.00\n",
      "RF_1c(ENP_MARGIN/4) =  -3.00\n",
      "RF_1c(ENP_MARGIN/2) =  -3.00\n",
      "RF_1c(ENP_MARGIN)   =  -3.00\n",
      "\n",
      "RF_1c(BMAX/2) =  -3.00\n",
      "RF_1c(BMAX)   =  -3.00\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#PLOT REWARD FUNCTIONS\n",
    "x = np.arange(0,capm.BMAX)\n",
    "y = [capm.rewardfn() for capm.btrack in x]\n",
    "\n",
    "fig = plt.figure(figsize=(10,5))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.set_title('REWARD FUNCTION 1c')\n",
    "ax.set_xlabel('BMEAN/BMAX')\n",
    "ax.set_ylabel('Reward')\n",
    "ax.axvline((capm.ENP_MARGIN)/capm.BMAX, color='g',alpha=0.75, linestyle='--')\n",
    "ax.axvline(1-(capm.BSAFE_LO)/capm.BMAX, color='c',alpha=0.75, linestyle='-.')\n",
    "ax.axvline(  (capm.BSAFE_HI)/capm.BMAX, color='b',alpha=0.75, linestyle=\"-.\")\n",
    "ax.axvline(1- (capm.BLIM_LO)/capm.BMAX, color='r',alpha=0.75, linestyle=':')\n",
    "ax.axvline(   (capm.BLIM_HI)/capm.BMAX, color='m',alpha=0.75, linestyle=\":\")\n",
    "ax.plot(x/capm.BMAX,y)\n",
    "ax.grid(True)\n",
    "plt.show()\n",
    "\n",
    "capm.enp = 0;            print(\"RF_1c(0)            = {:6.2f}\".format(capm.rewardfn()) )\n",
    "capm.enp = capm.ENP_MARGIN/4; print(\"RF_1c(ENP_MARGIN/4) = {:6.2f}\".format(capm.rewardfn()) )\n",
    "capm.enp = capm.ENP_MARGIN/2; print(\"RF_1c(ENP_MARGIN/2) = {:6.2f}\".format(capm.rewardfn()) )\n",
    "capm.enp = capm.ENP_MARGIN;   print(\"RF_1c(ENP_MARGIN)   = {:6.2f}\".format(capm.rewardfn()) )\n",
    "print(\"\");\n",
    "capm.enp = capm.BMAX/2; print(\"RF_1c(BMAX/2) = {:6.2f}\".format(capm.rewardfn()) )\n",
    "capm.enp = capm.BMAX;   print(\"RF_1c(BMAX)   = {:6.2f}\".format(capm.rewardfn()) )\n",
    "print(\"\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRAINING STARTS\n",
    "tic = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRAIN \n",
    "dqn = DQN()\n",
    "# for recording weights\n",
    "oldfc1 = dqn.eval_net.fc1.weight.data.cpu().numpy().flatten()\n",
    "old2fc1 = oldfc1\n",
    "\n",
    "# oldfc2 = dqn.eval_net.fc2.weight.data.cpu().numpy().flatten()\n",
    "# old2fc2 = oldfc2\n",
    "\n",
    "# oldfc3 = dqn.eval_net.fc3.weight.data.cpu().numpy().flatten()\n",
    "# old2fc3 = oldfc3\n",
    "\n",
    "oldout = dqn.eval_net.fc_out.weight.data.cpu().numpy().flatten()\n",
    "old2out = oldout\n",
    "########################################\n",
    "\n",
    "change_hr = 0 #when dqn target_net is updated by eval_net\n",
    "avg_reward_rec = [] #record the yearly average rewards over the entire duration of training\n",
    "batt_violation_rec = []\n",
    "day_violation_rec = []\n",
    "\n",
    "print('Device: ', dqn.device)\n",
    "#TRAINING STARTS\n",
    "tic = datetime.now()\n",
    "\n",
    "e_rec = []\n",
    "lr_rec = []\n",
    "for iteration in range(NO_OF_ITERATIONS):\n",
    "    # EPSILON SCHEDULING\n",
    "    e_slope = 5\n",
    "    e_start = 0.5\n",
    "    e_inflection_point = 50\n",
    "    EPSILON = e_start + (1-e_start)/(1 + np.exp(-(iteration-e_inflection_point)/e_slope))\n",
    "\n",
    "    # LR SCEHDULING\n",
    "    lr_slope = 3\n",
    "    lr_start = 0\n",
    "    lr_inflection_point = 2\n",
    "    if iteration <=50:\n",
    "        lrate =  (lr_start + (1-lr_start)/(1 + np.exp(-(iteration-lr_inflection_point)/lr_slope)))*1e-4\n",
    "    else:\n",
    "        lrate = 0.95*(lrate-lrate*0.1)+0.2*1e-5\n",
    "    dqn.optimizer = torch.optim.Adam(dqn.eval_net.parameters(), lr=lrate)\n",
    "#     dqn.optimizer = torch.optim.Adam(dqn.eval_net.parameters(), lr=lrate, weight_decay=WT_DECAY))\n",
    "    lr_rec= np.append(lr_rec,lrate)\n",
    "\n",
    "    LOCATION    = 'wakkanai'#random.choice(['tokyo','wakkanai','minamidaito'])\n",
    "    YEAR        = random.choice(np.arange(2000,2010))\n",
    "    \n",
    "    capm        = CAPM(LOCATION,YEAR,shuffle=False, trainmode=False) #instantiate the CAPM class\n",
    "    capm.eno    = ENO(LOCATION,YEAR, shuffle=False, day_balance=False) #instantiate the environment inside the CAPM class\n",
    "    capm.HMAX   = capm.eno.SMAX #maximum power output of solar cell is set in CAPM object using the value in ENO object\n",
    "\n",
    "\n",
    "    s, r, day_end, year_end = capm.reset(batt=0.8*capm.BMAX)\n",
    "    yr_record      = np.empty(4)\n",
    "    transition_rec = np.zeros((capm.eno.TIME_STEPS, N_STATES * 2 + 2)) #record all the transition in one day\n",
    "\n",
    "    while True:\n",
    "        a = dqn.choose_action(stdize(s))\n",
    "        yr_record = np.vstack((yr_record, [s[0],s[2],r, a]))\n",
    "\n",
    "        # take action\n",
    "        s_, r, day_end, year_end = capm.step(a)\n",
    "        \n",
    "        temp_transitions                = np.hstack((stdize(s), [a, r], stdize(s_)))\n",
    "        transition_rec[capm.eno.hr-1,:] = temp_transitions\n",
    "\n",
    "        if (day_end):\n",
    "            transition_rec[:,5]  = r #broadcast reward to all states\n",
    "            decay_factor         = [i for i in (LAMBDA**n for n in reversed(range(0, capm.eno.TIME_STEPS)))]\n",
    "            transition_rec[:,5]  = transition_rec[:,5] * decay_factor #decay reward proportionately\n",
    "            dqn.store_day_transition(transition_rec)\n",
    "\n",
    "        if dqn.good_memory_counter > MEMORY_CAPACITY and dqn.bad_memory_counter > MEMORY_CAPACITY:\n",
    "            dqn.learn()\n",
    "\n",
    "        if dqn.nettoggle:\n",
    "            change_hr = capm.eno.day*24+capm.eno.hr #to mark when the DQN is updated.\n",
    "            dqn.nettoggle = not dqn.nettoggle\n",
    "\n",
    "        if (year_end):\n",
    "            break\n",
    "\n",
    "        # transition to new state\n",
    "        s = s_\n",
    "\n",
    "    yr_record = np.delete(yr_record, 0, 0)     #remove the first row which is garbage\n",
    "    hourly_yr_reward_rec = yr_record[:,2]      #extract reward information from the record array\n",
    "    yr_reward_rec = hourly_yr_reward_rec[::24] #only consider terminal rewards\n",
    "\n",
    "    print('\\nIteration {}:  {}, {} '.format(iteration, LOCATION.upper(), YEAR))\n",
    "    print('EPSILON = {:6.3e}'.format(EPSILON))\n",
    "    for param_group in dqn.optimizer.param_groups:\n",
    "        print('LR = {:6.3e}'.format(param_group['lr']))\n",
    "    print(\"Average Terminal Reward  = {:6.3f}\".format(np.mean(yr_reward_rec)))\n",
    "    print(\"Day Violations           = {:6d}\".format(capm.violation_counter))\n",
    "    print(\"Battery Limit Violations = {:6d}\".format(capm.batt_violations))\n",
    "    print(\"Action MEAN              = {:6.3f}\".format(np.mean(yr_record[:,-1] + 1)))\n",
    "    print(\"Action STD DEV           = {:6.3f}\".format(np.std(yr_record[:,-1] + 1)))\n",
    "   \n",
    "    # Log the average reward in avg_reward_rec to plot later in the learning curve graph figure\n",
    "    avg_reward_rec      = np.append(avg_reward_rec, np.mean(yr_reward_rec))\n",
    "    day_violation_rec   = np.append(day_violation_rec, capm.violation_counter)\n",
    "    batt_violation_rec  = np.append(batt_violation_rec, capm.batt_violations)\n",
    "\n",
    "###########################################################################################\n",
    "###########################################################################################\n",
    "#   PLOT battery levels, hourly rewards and the weights\n",
    "    \n",
    "    #PLOT BATTERY AND REWARD\n",
    "    fig = plt.figure(figsize=(24,3))\n",
    "    TIME_STEPS = capm.eno.TIME_STEPS\n",
    "    NO_OF_DAYS = capm.eno.NO_OF_DAYS\n",
    "    DAY_SPACING = 15\n",
    "    TICK_SPACING = TIME_STEPS*DAY_SPACING\n",
    "    \n",
    "    #plot battery\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.plot(np.arange(0,TIME_STEPS*NO_OF_DAYS),  yr_record[:,0],'r')\n",
    "    ax.plot(np.arange(0,TIME_STEPS*NO_OF_DAYS), np.ones_like(yr_record[:,0])*capm.BOPT/capm.BMAX, 'k--', alpha=0.5)\n",
    "    ax.plot(np.arange(0,TIME_STEPS*NO_OF_DAYS), np.ones_like(yr_record[:,0])*capm.BLIM_LO/capm.BMAX, 'r:')\n",
    "    ax.plot(np.arange(0,TIME_STEPS*NO_OF_DAYS), np.ones_like(yr_record[:,0])*capm.BLIM_HI/capm.BMAX, 'r:')\n",
    "    ax.plot(np.arange(0,TIME_STEPS*NO_OF_DAYS), np.ones_like(yr_record[:,0])*(capm.BOPT+capm.ENP_MARGIN /2) /capm.BMAX, 'g:')\n",
    "    ax.plot(np.arange(0,TIME_STEPS*NO_OF_DAYS), np.ones_like(yr_record[:,0])*(capm.BOPT-capm.ENP_MARGIN/2)/capm.BMAX, 'g:')\n",
    "    ax.set_ylim([0,1])\n",
    "    ax.axvline(x=change_hr)\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(TICK_SPACING))\n",
    "\n",
    "    #plot hourly reward\n",
    "    ax0 = ax.twinx()\n",
    "    ax0.plot(hourly_yr_reward_rec, color='y',alpha=0.4)\n",
    "    ax0.set_ylim(-4,2)\n",
    "    \n",
    "    plt.show()\n",
    "# # #################################################################\n",
    "#     # PLOT WEIGHTS\n",
    "#     fig = plt.figure(figsize=(18,6))\n",
    "\n",
    "#     ax1 = fig.add_subplot(211)\n",
    "#     newfc1 = dqn.eval_net.fc1.weight.data.cpu().numpy().flatten()\n",
    "#     xaxis = np.arange(0,newfc1.shape[0])\n",
    "#     ax1.bar(xaxis, old2fc1, color='b', alpha = 0.3)\n",
    "#     ax1.bar(xaxis, oldfc1,  color='b', alpha = 0.5)\n",
    "#     ax1.bar(xaxis, newfc1,  color='b', alpha = 1.0)\n",
    "#     ax1.set_title(\"FC1\")\n",
    "# #     ax1.set_ylim([-4,4])\n",
    "#     ax1.set_ylabel(\"Weight Value\")\n",
    "\n",
    "#     axO = fig.add_subplot(212)\n",
    "#     newout = dqn.eval_net.fc_out.weight.data.cpu().numpy().flatten()\n",
    "#     xaxis = np.arange(0,newout.shape[0])\n",
    "#     axO.bar(xaxis, old2out, color='g', alpha = 0.3)\n",
    "#     axO.bar(xaxis, oldout,  color='g', alpha = 0.5)\n",
    "#     axO.bar(xaxis, newout,  color='g', alpha = 1.0)\n",
    "#     axO.set_title(\"FC OUT\")\n",
    "# #     axO.set_ylim([-4,4])\n",
    "#     axO.set_ylabel(\"Weight Value\")\n",
    "\n",
    "#     fig.tight_layout()\n",
    "#     plt.show()\n",
    "# # #################################################################\n",
    "\n",
    "#     # PLOT HISTOGRAM OF WEIGHTS\n",
    "#     fig = plt.figure(figsize=(18,6))\n",
    "\n",
    "#     ax1 = fig.add_subplot(211)\n",
    "#     newfc1 = dqn.eval_net.fc1.weight.data.cpu().numpy().flatten()\n",
    "#     xaxis = np.arange(0,newfc1.shape[0])\n",
    "# #     ax1.hist(old2fc1, density = False, bins=HIDDEN_LAYER, rwidth=0.95, color='b' , alpha = 0.1 )\n",
    "# #     ax1.hist(oldfc1,  density = False, bins=HIDDEN_LAYER, rwidth=0.95, color='b' , alpha = 0.3 )\n",
    "#     ax1.hist(newfc1,  density = False, bins=HIDDEN_LAYER, rwidth=0.95, color='b' , alpha = 0.6 )\n",
    "#     ax1.set_title(\"FC1\")\n",
    "#     ax1.set_xlabel(\"Weight Value\")\n",
    "\n",
    "\n",
    "#     axO = fig.add_subplot(212)\n",
    "#     newout = dqn.eval_net.fc_out.weight.data.cpu().numpy().flatten()\n",
    "#     xaxis = np.arange(0,newout.shape[0])\n",
    "# #     axO.hist(old2out, density = False, bins=HIDDEN_LAYER, rwidth=0.95, color='g' , alpha = 0.1)\n",
    "# #     axO.hist(oldout,  density = False, bins=HIDDEN_LAYER, rwidth=0.95, color='g' , alpha = 0.3)\n",
    "#     axO.hist(newout,  density = False, bins=HIDDEN_LAYER, rwidth=0.95, color='g' , alpha = 0.6)\n",
    "#     axO.set_title(\"FC OUT\")\n",
    "#     axO.set_xlabel(\"Weight Value\")\n",
    "\n",
    "\n",
    "#     fig.tight_layout()\n",
    "#     plt.show()\n",
    "# # #################################################################    \n",
    "    \n",
    "#     old2fc1 = oldfc1\n",
    "#     oldfc1 = newfc1\n",
    "    \n",
    "#     old2out = oldout\n",
    "#     oldout = newout\n",
    "\n",
    "    # End of training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Train time: {}\\n'.format(datetime.now() - tic))\n",
    "torch.save(dqn.eval_net.state_dict(), './models/'+ 'demo_' + MODELNAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################################################################\n",
    "###########################################################################################\n",
    "\n",
    "#PLOT LR AND EPSILON SCHEDULING\n",
    "fig = plt.figure(figsize=(12,3))\n",
    "ax = fig.add_subplot(111)\n",
    "# ax.set_title(\"LR and EPSILON SCHEDULING V3\")\n",
    "ax.set_xlabel(\"ITERATION\")\n",
    "# ax.set_ylabel(\"LR\",      color = 'm')\n",
    "ax.plot(lr_rec,          color = 'm', alpha = 0.3,label=\"LR\")\n",
    "# ax.tick_params(axis='y', color = 'm')\n",
    "# ax.ticklabel_format(style='sci', axis='y', scilimits=(-6,-7))\n",
    "# ax.minorticks_on()\n",
    "\n",
    "# ax.set_axisbelow(True)\n",
    "ax.yaxis.set_ticklabels([])\n",
    "\n",
    "ax.grid(b=True, which='minor', linestyle=':',  color='k', alpha = 0.1)\n",
    "ax.grid(b=True, which='major', linestyle='-',  color='k', alpha = 0.1)\n",
    "\n",
    "ax_ = ax.twinx()\n",
    "# ax_.set_ylabel(\"EPSILON\", color = 'c')\n",
    "# ax_.tick_params(axis='y', color = 'c')\n",
    "# ax_.set_axisbelow(True)\n",
    "# ax_.minorticks_on()\n",
    "ax_.plot(e_rec,           color = 'c', alpha = 0.3, label=\"EPSILON\")\n",
    "ax_.yaxis.set_ticklabels([])\n",
    "\n",
    "# Plot the average reward log\n",
    "ax1 = ax.twinx()\n",
    "# ax1.set_ylabel(\"Terminal Reward\", color = 'b')\n",
    "# ax1.set_ylim([-10,2]);\n",
    "ax1.plot(avg_reward_rec,'b',label=\"BATT\")\n",
    "# ax1.tick_params(axis='y', colors='b')\n",
    "ax1.yaxis.set_ticklabels([])\n",
    "\n",
    "# Plot the violation record log\n",
    "ax2 = ax.twinx()\n",
    "# ax2.set_ylabel(\"Violations\",color = 'r')\n",
    "ax2.plot(day_violation_rec,'r', label=\"DAY VIOLATIONS\")\n",
    "ax2.plot(batt_violation_rec,'r',alpha=0.4, label=\"DOWNTIME\")\n",
    "for xpt in np.argwhere(batt_violation_rec<1):\n",
    "    ax2.axvline(x=xpt,color='g',linewidth='0.5')\n",
    "# ax2.set_ylim([0,50]);\n",
    "# ax2.tick_params(axis='y', colors='r')\n",
    "ax2.yaxis.set_ticklabels([])\n",
    "\n",
    "fig.legend(bbox_to_anchor=(1.1, 0.7))\n",
    "\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "###########################################################################################\n",
    "###########################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"ITERATION #0 :  LR = {:4.2e} @ EPSILON = {:4.2f}\".format(lr_rec[0],e_rec[0]))\n",
    "# print(\"ITERATION #10:  LR = {:4.2e} @ EPSILON = {:4.2f}\".format(lr_rec[10],e_rec[10]))\n",
    "# print(\"ITERATION #20:  LR = {:4.2e} @ EPSILON = {:4.2f}\".format(lr_rec[20],e_rec[20]))\n",
    "# print(\"ITERATION #50:  LR = {:4.2e} @ EPSILON = {:4.2f}\".format(lr_rec[50],e_rec[50]))\n",
    "# print(\"ITERATION #80:  LR = {:4.2e} @ EPSILON = {:4.2f}\".format(lr_rec[80],e_rec[80]))\n",
    "# print(\"ITERATION #99:  LR = {:4.2e} @ EPSILON = {:4.2f}\".format(lr_rec[99],e_rec[99]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S_FILENAME = './models/'+ 'demo_'+ MODELNAME\n",
    "# S_FILENAME = './models/'+ MODELNAME\n",
    "print(\"Loading MODEL from FILE: \", S_FILENAME)\n",
    "dqn = DQN()\n",
    "dqn.eval_net.load_state_dict(torch.load(S_FILENAME))\n",
    "dqn.eval_net.eval()\n",
    "print(\"DEVICE: \", dqn.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#VALIDATION PHASE\n",
    "print(\"***MEASURING PERFORMANCE OF THE MODEL***\")\n",
    "for LOCATION in ['wakkanai','aomori','tokyo','fukuoka','minamidaito']:\n",
    "    results = np.empty(4)\n",
    "\n",
    "    for YEAR in np.arange(2000,2019):\n",
    "        capm      = CAPM(LOCATION,YEAR,shuffle=False, trainmode=False) #instantiate the CAPM class\n",
    "        capm.eno  = ENO(LOCATION,YEAR, shuffle=False, day_balance=False) #instantiate the environment inside the CAPM class\n",
    "        capm.HMAX = capm.eno.SMAX #maximum power output of solar cell is set in CAPM object using the value in ENO object\n",
    "\n",
    "        s, r, day_end, year_end = capm.reset()\n",
    "        yr_test_record = np.empty(4)\n",
    "\n",
    "        while True:\n",
    "            a = dqn.choose_greedy_action(stdize(s))\n",
    "            yr_test_record = np.vstack((yr_test_record, [s[0],s[2],r, a])) #record battery, henergy, reward and action\n",
    "            s_, r, day_end, year_end = capm.step(a)\n",
    "            if year_end:\n",
    "                break\n",
    "            s = s_\n",
    "\n",
    "        yr_test_record = np.delete(yr_test_record, 0, 0) #remove the first row which is garbage\n",
    "        yr_test_reward_rec = yr_test_record[:,2]\n",
    "        yr_test_reward_rec = yr_test_reward_rec[::24] #annual average reward\n",
    "        results = np.vstack((results, [int(YEAR), np.mean(yr_test_reward_rec), int(capm.violation_counter), int(capm.batt_violations)]))\n",
    "\n",
    "    ###########################################################################################\n",
    "    ###########################################################################################\n",
    "        #     Plot the reward and battery for the entire year run\n",
    "        title = LOCATION.upper() + ',' + str(YEAR)\n",
    "        NO_OF_DAYS = capm.eno.NO_OF_DAYS\n",
    "\n",
    "        fig = plt.figure(figsize=(24,6))\n",
    "        fig.suptitle(title, fontsize=15)\n",
    "\n",
    "        ax1 = fig.add_subplot(211)\n",
    "        ax1.plot(yr_test_reward_rec)\n",
    "        ax1.set_title(\"\\n\\nYear Run Reward\")\n",
    "        ax1.set_ylim([-4,2])\n",
    "\n",
    "        ax2 = fig.add_subplot(212)\n",
    "        ax2.plot(yr_test_record[:,0],'r')\n",
    "        ax2.plot(np.ones_like(yr_test_record[:,0])*capm.BOPT/capm.BMAX, 'k--')\n",
    "        ax2.plot(np.ones_like(yr_test_record[:,0])*capm.BLIM_LO/capm.BMAX, 'r:')\n",
    "        ax2.plot(np.ones_like(yr_test_record[:,0])*capm.BLIM_HI/capm.BMAX, 'r:')\n",
    "        ax2.plot(np.ones_like(yr_test_record[:,0])*(capm.BOPT+capm.ENP_MARGIN /2) /capm.BMAX, 'g:')\n",
    "        ax2.plot(np.ones_like(yr_test_record[:,0])*(capm.BOPT-capm.ENP_MARGIN/2)/capm.BMAX, 'g:')\n",
    "\n",
    "        ax2.set_title(\"\\n\\nYear Run Battery\")\n",
    "        ax2.set_ylim([0,1])\n",
    "        plt.sca(ax2)\n",
    "        plt.xticks(np.arange(0, NO_OF_DAYS*24, 50*24),np.arange(0,NO_OF_DAYS,50))\n",
    "        fig.tight_layout()\n",
    "        plt.show()\n",
    "    ###########################################################################################\n",
    "    ###########################################################################################\n",
    "    results = np.delete(results,0,0)\n",
    "    print(\"\\n\")\n",
    "    print(LOCATION.upper())\n",
    "    print('YEAR\\tAVG_RWD\\t\\tVIOLATIONS')\n",
    "    print('\\t\\t\\tDAY\\tBATT')\n",
    "\n",
    "    for x in np.arange(0,results.shape[0]):\n",
    "        print('{}\\t {}\\t\\t{}\\t {}'.format(int(results[x,0]), np.around(results[x,1],2), int(results[x,2]), int(results[x,-1])))\n",
    "\n",
    "    print(\"\\nTOTAL Day Violations:  \",np.sum(results[:, 2]))\n",
    "    print(\"TOTAL Batt Violations: \",np.sum(results[:,-1]))\n",
    "    print(\"************************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\nRun time: {}'.format(datetime.now() - tic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOCATION = 'tokyo'\n",
    "YEAR = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capm = CAPM(LOCATION,YEAR,shuffle=False, trainmode=False) #instantiate the CAPM class\n",
    "capm.eno = ENO(LOCATION,YEAR, shuffle=False, day_balance=False) #instantiate the environment inside the CAPM class\n",
    "capm.HMAX = capm.eno.SMAX #maximum power output of solar cell is set in CAPM object using the value in ENO object\n",
    "\n",
    "s, r, day_end, year_end = capm.reset()\n",
    "yr_test_record = np.empty(4)\n",
    "\n",
    "while True:\n",
    "    a = dqn.choose_greedy_action(stdize(s))\n",
    "\n",
    "    #state = [batt, enp, henergy, fcast]\n",
    "    yr_test_record = np.vstack((yr_test_record, [s[0],s[2],r, a])) #record battery, henergy, reward and action\n",
    "\n",
    "    # take action\n",
    "    s_, r, day_end, year_end = capm.step(a)\n",
    "\n",
    "    if year_end:\n",
    "        break\n",
    "\n",
    "    s = s_\n",
    "\n",
    "yr_test_record = np.delete(yr_test_record, 0, 0) #remove the first row which is garbage\n",
    "yr_test_reward_rec = yr_test_record[:,2]\n",
    "yr_test_reward_rec = yr_test_reward_rec[::24]\n",
    "\n",
    "title = LOCATION.upper() + ',' + str(YEAR)\n",
    "NO_OF_DAYS = capm.eno.NO_OF_DAYS\n",
    "\n",
    "fig = plt.figure(figsize=(24,6))\n",
    "fig.suptitle(title, fontsize=15)\n",
    "\n",
    "#     ax1 = fig.add_subplot(211)\n",
    "#     ax1.plot(yr_test_reward_rec)\n",
    "#     ax1.set_title(\"\\n\\nYear Run Reward\")\n",
    "#     ax1.set_ylim([-3,3])\n",
    "\n",
    "#Plot the reward and battery for the entire year run\n",
    "ax2 = fig.add_subplot(111)\n",
    "ax2.plot(yr_test_record[:,0],'r')\n",
    "ax2.plot(np.ones_like(yr_test_record[:,0])*capm.BOPT/capm.BMAX, 'k--')\n",
    "ax2.plot(np.ones_like(yr_test_record[:,0])*capm.BLIM_LO/capm.BMAX, 'r:')\n",
    "ax2.plot(np.ones_like(yr_test_record[:,0])*capm.BLIM_HI/capm.BMAX, 'r:')\n",
    "ax2.plot(np.ones_like(yr_test_record[:,0])*(capm.BOPT+capm.ENP_MARGIN /2) /capm.BMAX, 'g:')\n",
    "ax2.plot(np.ones_like(yr_test_record[:,0])*(capm.BOPT-capm.ENP_MARGIN/2)/capm.BMAX, 'g:')\n",
    "ax2.set_title(\"\\n\\nYear Run Battery\")\n",
    "ax2.set_ylim([0,1])\n",
    "plt.sca(ax2)\n",
    "plt.xticks(np.arange(0, NO_OF_DAYS*24, 50*24),np.arange(0,NO_OF_DAYS,50))\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DAY_START = 320\n",
    "DAY_END   = 325"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the reward and battery for the entire year run on a day by day basis\n",
    "title = LOCATION.upper() + ',' + str(YEAR)\n",
    "TIME_AXIS = np.arange(0,capm.eno.TIME_STEPS)\n",
    "for DAY in range(DAY_START,DAY_END):\n",
    "    START = DAY*24\n",
    "    END = START+24\n",
    "\n",
    "    daytitle = title + ' - DAY ' + str(DAY)\n",
    "    fig = plt.figure(figsize=(16,4))\n",
    "    st = fig.suptitle(daytitle)\n",
    "\n",
    "    ax2 = fig.add_subplot(121)\n",
    "    ax2.plot(yr_test_record[START:END,1],'g')\n",
    "    ax2.set_title(\"HARVESTED ENERGY\")\n",
    "    ax2.set_xlabel(\"Hour\")\n",
    "    ax2.set_ylim([0,1.05])\n",
    "    \n",
    "    ax2.text(0.1, 0.6, \"TENP = %.2f\\n\" %(capm.BOPT/capm.BMAX-yr_test_record[END,0]),fontsize=11, ha='left')\n",
    "    ax2.text(0.1, 0.5, \"BMEAN = %.2f\\n\" %(np.mean(yr_test_record[START:END,0])),fontsize=11, ha='left')\n",
    "    ax2.text(0.1, 0.4, \"BINIT = %.2f\\n\" %(yr_test_record[START,0]),fontsize=11, ha='left')\n",
    "    if END < (capm.eno.NO_OF_DAYS*capm.eno.TIME_STEPS):\n",
    "        ax2.text(0.1, 0.1, \"REWARD = %.2f\\n\" %(yr_test_record[END,2]),fontsize=13, ha='left')\n",
    "        \n",
    "    #plot battery for year run\n",
    "    ax1 = fig.add_subplot(122)\n",
    "    ax1.plot(TIME_AXIS,              yr_test_record[START:END,0],'r')\n",
    "    ax1.plot(TIME_AXIS, np.ones_like(yr_test_record[START:END,0])*capm.BOPT/capm.BMAX, 'r--')\n",
    "    ax1.plot(TIME_AXIS, np.ones_like(yr_test_record[START:END,0])*capm.BLIM_LO/capm.BMAX, 'r-.',alpha=0.5)\n",
    "    ax1.plot(TIME_AXIS, np.ones_like(yr_test_record[START:END,0])*capm.BLIM_HI/capm.BMAX, 'r-.',alpha=0.5)\n",
    "    ax1.plot(TIME_AXIS, np.ones_like(yr_test_record[START:END,0])*(capm.BOPT+capm.ENP_MARGIN /2) /capm.BMAX, 'g:',alpha=0.5)\n",
    "    ax1.plot(TIME_AXIS, np.ones_like(yr_test_record[START:END,0])*(capm.BOPT-capm.ENP_MARGIN/2)/capm.BMAX, 'g:',alpha=0.5)\n",
    "    \n",
    "    ax1.set_title(\"YEAR RUN TEST\")\n",
    "    ax1.set_xlabel(\"Hour\")\n",
    "    ax1.set_ylabel('Battery', color='r',fontsize=12)\n",
    "    ax1.set_ylim([-0.05,1.05])\n",
    "\n",
    "    #plot actions for year run\n",
    "    ax1a = ax1.twinx()\n",
    "    ax1a.plot(yr_test_record[START:END,3]+1)\n",
    "    ax1a.set_ylim([0,N_ACTIONS])\n",
    "    ax1a.set_ylabel('Duty Cycle', color='b',fontsize=12)\n",
    "    ax1a.set_ylim([0,10.25])\n",
    "\n",
    "\n",
    "    fig.tight_layout()\n",
    "    st.set_y(0.95)\n",
    "    fig.subplots_adjust(top=0.75)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
