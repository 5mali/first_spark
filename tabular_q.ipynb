{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from datetime import datetime\n",
    "import os\n",
    "from os.path import dirname, abspath, join\n",
    "from os import getcwd\n",
    "import sys\n",
    "\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ENO(object):\n",
    "    \n",
    "    #no. of forecast types is 6 ranging from 0 to 5\n",
    "  \n",
    "    def __init__(self, location='tokyo', year=2010, shuffle=False, day_balance=False):\n",
    "        self.location = location\n",
    "        self.year = year\n",
    "        self.day = None\n",
    "        self.hr = None\n",
    "        \n",
    "        self.shuffle = shuffle\n",
    "        self.day_balance = day_balance\n",
    "\n",
    "        self.TIME_STEPS = None #no. of time steps in one episode\n",
    "        self.NO_OF_DAYS = None #no. of days in one year\n",
    "        \n",
    "        self.NO_OF_DAYTYPE = 10 #no. of daytypes\n",
    "        self.daycounter = 0 #to count number of days that have been passed\n",
    "        \n",
    "        self.sradiation = None #matrix with GSR for the entire year\n",
    "        self.senergy = None #matrix with harvested energy data for the entire year\n",
    "        self.fforecast = None #array with forecast values for each day\n",
    "        \n",
    "\n",
    "        self.henergy = None #harvested energy variable\n",
    "        self.fcast = None #forecast variable\n",
    "        self.sorted_days = [] #days sorted according to day type\n",
    "        \n",
    "        self.SMAX = 1000 # 1 Watt Solar Panel\n",
    "\n",
    "    \n",
    "    #function to get the solar data for the given location and year and prep it\n",
    "    def get_data(self):\n",
    "        #solar_data/CSV files contain the values of GSR (Global Solar Radiation in MegaJoules per meters squared per hour)\n",
    "        #weather_data/CSV files contain the weather summary from 06:00 to 18:00 and 18:00 to 06:00+1\n",
    "        location = self.location\n",
    "        year = self.year\n",
    "\n",
    "        THIS_DIR = getcwd()\n",
    "        SDATA_DIR = abspath(join(THIS_DIR, 'solar_data'))  #abspath(join(THIS_DIR, '../../..', 'data'))\n",
    "        \n",
    "        sfile = SDATA_DIR + '/' + location +'/' + str(year) + '.csv'\n",
    "        \n",
    "        #skiprows=4 to remove unnecessary title texts\n",
    "        #usecols=4 to read only the Global Solar Radiation (GSR) values\n",
    "        solar_radiation = pd.read_csv(sfile, skiprows=4, encoding='shift_jisx0213', usecols=[4])\n",
    "      \n",
    "        #convert dataframe to numpy array\n",
    "        solar_radiation = solar_radiation.values\n",
    "\n",
    "        #convert missing data in CSV files to zero\n",
    "        solar_radiation[np.isnan(solar_radiation)] = 0\n",
    "\n",
    "        #reshape solar_radiation into no_of_daysx24 array\n",
    "        solar_radiation = solar_radiation.reshape(-1,24)\n",
    "\n",
    "        if(self.shuffle): #if class instatiation calls for shuffling the day order. Required when learning\n",
    "            np.random.shuffle(solar_radiation) \n",
    "        self.sradiation = solar_radiation\n",
    "        \n",
    "        #GSR values (in MJ/sq.mts per hour) need to be expressed in mW\n",
    "        # Conversion is accomplished by \n",
    "        # solar_energy = GSR(in MJ/m2/hr) * 1e6 * size of solar cell * efficiency of solar cell /(60x60) *1000 (to express in mW)\n",
    "        # the factor of 2 in the end is assuming two solar cells\n",
    "        self.senergy = 2*self.sradiation * 1e6 * (55e-3 * 70e-3) * 0.15 * 1000/(60*60)\n",
    "\n",
    "        return 0\n",
    "    \n",
    "    #function to map total day radiation into type of day ranging from 0 to 5\n",
    "    #the classification into day types is quite arbitrary. There is no solid logic behind this type of classification.\n",
    "    \n",
    "    def get_day_state(self,tot_day_radiation):\n",
    "        bin_edges = np.array([0, 3.5, 6.5, 9.0, 12.5, 15.5, 18.5, 22.0, 25, 28])\n",
    "        for k in np.arange(1,bin_edges.size):\n",
    "            if (bin_edges[k-1] < tot_day_radiation <= bin_edges[k]):\n",
    "                day_state = k -1\n",
    "            else:\n",
    "                day_state = bin_edges.size - 1\n",
    "        return int(day_state)\n",
    "    \n",
    "    def get_forecast(self):\n",
    "        #create a perfect forecaster.\n",
    "        tot_day_radiation = np.sum(self.sradiation, axis=1) #contains total solar radiation for each day\n",
    "        get_day_state = np.vectorize(self.get_day_state)\n",
    "        self.fforecast = get_day_state(tot_day_radiation)\n",
    "        \n",
    "        #sort days depending on the type of day and shuffle them; maybe required when learning\n",
    "        for fcast in range(0,6):\n",
    "            fcast_days = ([i for i,x in enumerate(self.fforecast) if x == fcast])\n",
    "            np.random.shuffle(fcast_days)\n",
    "            self.sorted_days.append(fcast_days)\n",
    "        return 0\n",
    "    \n",
    "    def reset(self,day=0): #it is possible to reset to the beginning of a certain day\n",
    "        \n",
    "        self.get_data() #first get data for the given year\n",
    "        self.get_forecast() #calculate the forecast\n",
    "        \n",
    "        self.TIME_STEPS = self.senergy.shape[1]\n",
    "        self.NO_OF_DAYS = self.senergy.shape[0]\n",
    "        \n",
    "        self.day = day\n",
    "        self.hr = 0\n",
    "        \n",
    "        self.henergy = self.senergy[self.day][self.hr]\n",
    "        self.fcast = self.fforecast[self.day]\n",
    "        \n",
    "        end_of_day = False\n",
    "        end_of_year = False\n",
    "        return [self.henergy, self.fcast, end_of_day, end_of_year]\n",
    "\n",
    "    \n",
    "    def step(self):\n",
    "        end_of_day = False\n",
    "        end_of_year = False\n",
    "        if not(self.day_balance): #if daytype balance is not required\n",
    "            if(self.hr < self.TIME_STEPS - 1):\n",
    "                self.hr += 1\n",
    "                self.henergy = self.senergy[self.day][self.hr] \n",
    "                self.fcast = self.fforecast[self.day]\n",
    "            else:\n",
    "                if(self.day < self.NO_OF_DAYS -1):\n",
    "                    end_of_day = True\n",
    "                    self.hr = 0\n",
    "                    self.day += 1\n",
    "                    self.henergy = self.senergy[self.day][self.hr] \n",
    "                    self.fcast = self.fforecast[self.day]\n",
    "                else:\n",
    "                    end_of_day = True\n",
    "                    end_of_year = True\n",
    "                    \n",
    "        else: #when training, we want all daytypes to be equally represented for robust policy\n",
    "              #obviously, the days are going to be in random order\n",
    "            if(self.hr < self.TIME_STEPS - 1):\n",
    "                self.hr += 1\n",
    "                self.henergy = self.senergy[self.day][self.hr]\n",
    "                self.fcast = self.fforecast[self.day]\n",
    "            else:\n",
    "                if(self.daycounter < self.NO_OF_DAYS -1):\n",
    "                    end_of_day = True\n",
    "                    self.daycounter += 1\n",
    "                    self.hr = 0\n",
    "                    daytype = random.choice(np.arange(0,self.NO_OF_DAYTYPE)) #choose random daytype\n",
    "                    self.day = np.random.choice(self.sorted_days[daytype]) #choose random day from that daytype\n",
    "                    self.henergy = self.senergy[self.day][self.hr] \n",
    "                    self.fcast = self.fforecast[self.day]\n",
    "                else: \n",
    "                    end_of_day = True\n",
    "                    end_of_year = True\n",
    "                    self.daycounter = 0\n",
    "        \n",
    "        \n",
    "        return [self.henergy, self.fcast, end_of_day, end_of_year]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CAPM (object):\n",
    "    def __init__(self,location='tokyo', year=2010, shuffle=False, trainmode=False):\n",
    "\n",
    "        #all energy values i.e. BMIN, BMAX, BOPT, HMAX are in mWhr. Assuming one timestep is one hour\n",
    "        \n",
    "        self.BMIN = 0.0                #Minimum battery level that is tolerated. Maybe non-zero also\n",
    "        self.BMAX = 10000.0            #Max Battery Level. May not necessarily be equal to total batter capacity [3.6V x 2500mAh]\n",
    "        self.BOPT = 0.5 * self.BMAX    #Optimal Battery Level. Assuming 50% of battery is the optimum\n",
    "        self.BLIM_LO = 0.15*self.BMAX\n",
    "        self.BLIM_HI = 0.95*self.BMAX\n",
    "        self.BSAFE_LO = 0.35*self.BMAX\n",
    "        self.BSAFE_HI = 0.65*self.BMAX\n",
    "        \n",
    "        self.ENP_MARGIN = 0.3*self.BMAX\n",
    "\n",
    "        \n",
    "        self.HMIN = 0      #Minimum energy that can be harvested by the solar panel.\n",
    "        self.HMAX = None   #Maximum energy that can be harvested by the solar panel. [500mW]\n",
    "        \n",
    "        self.DMAX = 500      #Maximum energy that can be consumed by the node in one time step. [~ 3.6V x 135mA]\n",
    "        self.N_ACTIONS = 10  #No. of different duty cycles possible\n",
    "        self.DMIN = self.DMAX/self.N_ACTIONS #Minimum energy that can be consumed by the node in one time step. [~ 3.6V x 15mA]\n",
    "        \n",
    "        self.binit = None     #battery at the beginning of day\n",
    "        self.btrack = []      #track the mean battery level for each day\n",
    "        self.atrack = []      #track the duty cycles for each day\n",
    "        self.htrack = []      #track the harvested for each day\n",
    "        self.batt = None      #battery variable\n",
    "        self.enp = None       #enp at end of hr\n",
    "        self.henergy = None   #harvested energy variable\n",
    "        self.fcast = None     #forecast variable\n",
    "        \n",
    "        self.MUBATT = 0.6\n",
    "        self.SDBATT = 0.02\n",
    "        \n",
    "        self.MUHENERGY = 0.5\n",
    "        self.SDHENERGY = 0.2\n",
    "        \n",
    "        self.MUENP = 0\n",
    "        self.SDENP = 0.02\n",
    "        \n",
    "        self.location  = location\n",
    "        self.year      = year\n",
    "        self.shuffle   = shuffle\n",
    "        self.trainmode = trainmode\n",
    "        self.eno       = None\n",
    "        \n",
    "        self.day_violation_flag = False\n",
    "        self.violation_flag     = False\n",
    "        self.violation_counter  = 0\n",
    "        \n",
    "        self.batt_violations    = 0\n",
    "\n",
    "        self.NO_OF_DAYTYPE      = 10 #no. of daytypes\n",
    " \n",
    "    def reset(self,day=0,batt=-1):\n",
    "        henergy, fcast, day_end, year_end = self.eno.reset(day) #reset the eno environment\n",
    "        self.violation_flag = False\n",
    "        self.violation_counter = 0\n",
    "        self.batt_violations = 0\n",
    "        \n",
    "        if(batt == -1):\n",
    "            self.batt = self.BOPT\n",
    "        else:\n",
    "            self.batt = batt\n",
    "            \n",
    "        self.batt = np.clip(self.batt, self.BMIN, self.BMAX)\n",
    "        self.binit = self.batt\n",
    "        self.btrack = np.append(self.btrack, self.batt) #track battery levels\n",
    "\n",
    "        self.enp = self.BOPT - self.batt\n",
    "#         self.enp = self.binit - self.batt #enp is calculated\n",
    "        self.henergy = np.clip(henergy, self.HMIN, self.HMAX) #clip henergy within HMIN and HMAX\n",
    "        self.fcast = fcast\n",
    "        \n",
    "        norm_batt    = self.batt    /self.BMAX\n",
    "        norm_enp     = self.enp     /self.BMAX\n",
    "        norm_henergy = self.henergy /self.HMAX\n",
    "        norm_fcast   = self.fcast   /(self.NO_OF_DAYTYPE-1)\n",
    "        c_state = [norm_batt, norm_enp, norm_henergy, norm_fcast] #continuous states\n",
    "\n",
    "        reward = 0\n",
    "        \n",
    "        return [c_state, reward, day_end, year_end]\n",
    "    \n",
    "    def getstate(self): #query the present state of the system\n",
    "        norm_batt    = self.batt    /self.BMAX\n",
    "        norm_enp     = self.enp     /self.BMAX\n",
    "        norm_henergy = self.henergy /self.HMAX\n",
    "        norm_fcast   = self.fcast   /(self.NO_OF_DAYTYPE-1)\n",
    "        c_state = [norm_batt, norm_enp, norm_henergy, norm_fcast] #continuous states\n",
    "\n",
    "        return c_state\n",
    "        \n",
    "    \n",
    "    #reward function\n",
    "    def rewardfn(self):\n",
    "        violation_penalty = 0\n",
    "        reward = 2 - 20*np.abs(self.enp)/self.BMAX\n",
    "#         if(self.day_violation_flag):\n",
    "#             violation_penalty += 3    #penalty for violating battery limits anytime during the day\n",
    "        return (reward - violation_penalty)\n",
    "    \n",
    "    def step(self, action):\n",
    "        day_end = False\n",
    "        year_end = False\n",
    "        self.violation_flag = False\n",
    "        reward = 0\n",
    "        self.atrack = np.append(self.atrack, action+1) #track duty cycles\n",
    "        self.htrack = np.append(self.htrack, self.henergy)\n",
    "\n",
    "#         action_var = np.abs(np.mean(self.atrack) - action)/9 #can vary from 0 to 1\n",
    "#         reward += 0.25*(0.5 - action_var ) #reward penalizing high duty cycle variance [-0.5 to 0.5]*0.25\n",
    "      \n",
    "        action = np.clip(action, 0, self.N_ACTIONS-1) #action values range from (0 to N_ACTIONS-1)\n",
    "        e_consumed = (action+1)*self.DMAX/self.N_ACTIONS   #energy consumed by the node\n",
    "        \n",
    "        \n",
    "        self.batt += (self.henergy - e_consumed)\n",
    "        if(self.batt <= self.BMIN or self.batt >= self.BMAX ):\n",
    "                self.batt_violations += 1\n",
    "        \n",
    "        if(self.batt < self.BLIM_LO or self.batt > self.BLIM_HI ):\n",
    "            self.violation_flag = True #penalty for violating battery limits everytime it happens\n",
    "#             reward -= 2\n",
    "#             if(self.batt < self.BLIM_LO): #battery depletion is more fatal than battery overflow\n",
    "#                 reward -= 2\n",
    "\n",
    "        if(self.violation_flag):\n",
    "            if(self.day_violation_flag == False): #penalty for violating battery limits anytime during the day - triggers once everyday\n",
    "                self.violation_counter += 1\n",
    "                self.day_violation_flag = True\n",
    "                \n",
    "        #calculate ENP before clipping\n",
    "        self.enp = self.BOPT - self.batt\n",
    "        \n",
    "        self.batt = np.clip(self.batt, self.BMIN, self.BMAX) #clip battery values within permitted level\n",
    "        self.btrack = np.append(self.btrack, self.batt) #track battery levels\n",
    "        \n",
    "        \n",
    "        #proceed to the next time step\n",
    "       \n",
    "        self.henergy, self.fcast, day_end, year_end = self.eno.step()\n",
    "        self.henergy = np.clip(self.henergy, self.HMIN, self.HMAX) #clip henergy within HMIN and HMAX\n",
    "                        \n",
    "        if(day_end): #if eno object flags that the day has ended then give reward\n",
    "            reward += self.rewardfn()\n",
    "            if (self.trainmode): #reset battery to optimal level if limits are exceeded when training\n",
    "#                 self.batt = np.random.uniform(self.DMAX*self.eno.TIME_STEPS/self.BMAX,0.8)*self.BMAX\n",
    "#                 if (self.violation_flag):\n",
    "                if np.random.uniform() < HELP : #occasionaly reset the battery\n",
    "                    self.batt = self.BOPT  \n",
    "            \n",
    "            self.day_violation_flag = False\n",
    "            self.binit = self.batt #this will be the new initial battery level for next day\n",
    "            self.btrack = [] #clear battery tracker\n",
    "            self.atrack = [] #clear duty cycle tracker\n",
    "            self.htrack = [] #clear henergy tracker\n",
    "   \n",
    "        norm_batt    = self.batt    /self.BMAX\n",
    "        norm_enp     = self.enp     /self.BMAX\n",
    "        norm_henergy = self.henergy /self.HMAX\n",
    "        norm_fcast   = self.fcast   /(self.NO_OF_DAYTYPE-1)\n",
    "        c_state = [norm_batt, norm_enp, norm_henergy, norm_fcast] #continuous states\n",
    "        \n",
    "        return [c_state, reward, day_end, year_end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Class definitions for NN model and learning algorithm\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(N_STATES, HIDDEN_LAYER)\n",
    "        nn.init.kaiming_uniform_(self.fc1.weight)\n",
    "        \n",
    "#         self.fc2 = nn.Linear(HIDDEN_LAYER, HIDDEN_LAYER)\n",
    "#         nn.init.kaiming_uniform_(self.fc2.weight)\n",
    "        \n",
    "#         self.fc3 = nn.Linear(HIDDEN_LAYER, HIDDEN_LAYER)\n",
    "#         nn.init.kaiming_uniform_(self.fc3.weight)\n",
    "\n",
    "        self.fc_out = nn.Linear(HIDDEN_LAYER, N_ACTIONS)\n",
    "        nn.init.xavier_uniform_(self.fc_out.weight) \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        if   (ACTIVATION==0): x = F.relu(x)\n",
    "        elif (ACTIVATION==1): x = F.leaky_relu(x)\n",
    "        else                : print(\"NN ACTIVATION: Error\")\n",
    "#         x = F.leaky_relu(x)\n",
    "#         x = self.fc2(x)\n",
    "#         x = F.relu(x)\n",
    "#         x = self.fc3(x)\n",
    "#         x = F.relu(x)\n",
    "        x = self.fc_out(x)\n",
    "        return x\n",
    "    \n",
    "class DQN(object):\n",
    "    def __init__(self):\n",
    "        if(GPU): \n",
    "            device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        else:\n",
    "            device = torch.device('cpu')\n",
    "        self.eval_net = Net()\n",
    "        self.eval_net.to(device)\n",
    "        self.device = device\n",
    "#         print(\"Neural net:\")\n",
    "#         print(self.eval_net)\n",
    "\n",
    "  \n",
    "    def get_qvals(self,x):\n",
    "        x = torch.unsqueeze(torch.FloatTensor(x), 0)\n",
    "        x = x.to(self.device)\n",
    "        actions_value = self.eval_net.forward(x)\n",
    "        actions_value = actions_value.to(torch.device(\"cpu\"))\n",
    "        actions_value = actions_value.data.numpy()\n",
    "        return actions_value\n",
    "    \n",
    "    def choose_greedy_action(self, x):\n",
    "        x = torch.unsqueeze(torch.FloatTensor(x), 0)\n",
    "        x = x.to(self.device)\n",
    "\n",
    "        # input only one sample\n",
    "        if True:   # greedy\n",
    "            actions_value = self.eval_net.forward(x)\n",
    "            actions_value = actions_value.to(torch.device(\"cpu\"))\n",
    "            action = torch.max(actions_value, 1)[1].data.numpy()\n",
    "            action = action[0] # return the argmax index\n",
    "        return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stdize(s):\n",
    "    MU_BATT = 0.5\n",
    "    SD_BATT = 0.15\n",
    "    \n",
    "    MU_ENP = 0\n",
    "    SD_ENP = 0.15\n",
    "    \n",
    "    MU_HENERGY = 0.35\n",
    "    SD_HENERGY = 0.25\n",
    "    \n",
    "    MU_FCAST = 0.42\n",
    "    SD_FCAST = 0.27\n",
    "    \n",
    "    norm_batt, norm_enp, norm_henergy, norm_fcast = s\n",
    "    \n",
    "    std_batt    = (norm_batt    - MU_BATT    )/SD_BATT\n",
    "    std_enp     = (norm_enp     - MU_ENP     )/SD_ENP\n",
    "    std_henergy = (norm_henergy - MU_HENERGY )/SD_HENERGY\n",
    "    std_fcast   = (norm_fcast   - MU_FCAST   )/SD_FCAST\n",
    "\n",
    "    return [std_batt, std_enp, std_henergy, std_fcast]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper Parameters\n",
    "N_ACTIONS           = 10           #no. of duty cycles (0 to 9)\n",
    "N_STATES            = 4            #number of state space parameter [batt, enp, henergy, fcast]\n",
    "GPU                 = False\n",
    "ACTIVATION          = 0            # 0 = RELU, 1 = Leaky RELU\n",
    "HIDDEN_LAYER        = 50\n",
    "\n",
    "LOCATION  = 'tokyo' #dummy location\n",
    "YEAR      =  2010 #dummy year\n",
    "capm      = CAPM(LOCATION,YEAR,shuffle=False, trainmode=False) #instantiate the CAPM class\n",
    "capm.eno  = ENO(LOCATION,YEAR, shuffle=False, day_balance=False) #instantiate the environment inside the CAPM class\n",
    "capm.HMAX = capm.eno.SMAX #maximum power output of solar cell is set in CAPM object using the value in ENO object\n",
    "\n",
    "BMAX          = capm.BMAX\n",
    "HMAX          = capm.HMAX\n",
    "NO_OF_DAYTYPE = capm.NO_OF_DAYTYPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL NAME:  A0_5526538.pt\n"
     ]
    }
   ],
   "source": [
    "NAME = \"A0\"\n",
    "seed_arg = 6\n",
    "seedlist = np.array([161, 314, 228, 271828, 230, 4271031, 5526538, 6610165, 9849252, 34534, 73422, 8765])\n",
    "seed = seedlist[seed_arg]\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "MODELNAME  = NAME + '_' + str(seed) + '.pt'\n",
    "print(\"MODEL NAME: \", MODELNAME)\n",
    "S_FILENAME = './models/'+ MODELNAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dqn = DQN();\n",
    "dqn.eval_net.load_state_dict(torch.load(S_FILENAME));\n",
    "dqn.eval_net.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUANTIZATION_LEVEL = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "batt_s    = np.linspace(0,       BMAX,            QUANTIZATION_LEVEL)\n",
    "enp_s     = np.linspace(-BMAX,   BMAX,          2*QUANTIZATION_LEVEL)\n",
    "henergy_s = np.linspace(0,       HMAX,            QUANTIZATION_LEVEL)\n",
    "fcast_s   = np.linspace(0,       NO_OF_DAYTYPE-1, NO_OF_DAYTYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discretize(batt, enp, henergy, fcast):\n",
    "        batt_state    = np.where(batt_s    >= batt)    [0][0]\n",
    "        enp_state     = np.where(enp_s     >= enp)     [0][0]\n",
    "        henergy_state = np.where(henergy_s >= henergy) [0][0]\n",
    "        fcast_state   = np.where(fcast_s   >= fcast)   [0][0]\n",
    "        \n",
    "        return [batt_state, enp_state, henergy_state, fcast_state]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denormalize(norm_s):\n",
    "    LOCATION = 'tokyo'\n",
    "    YEAR = 2010\n",
    "    capm      = CAPM(LOCATION,YEAR,shuffle=False, trainmode=False) #instantiate the CAPM class\n",
    "    capm.eno  = ENO(LOCATION,YEAR, shuffle=False, day_balance=False) #instantiate the environment inside the CAPM class\n",
    "    capm.HMAX = capm.eno.SMAX #maximum power output of solar cell is set in CAPM object using the value in ENO object\n",
    "    \n",
    "    true_batt    = norm_s[0]*capm.BMAX\n",
    "    true_enp     = norm_s[1]*capm.BMAX\n",
    "    true_henergy = norm_s[2]*capm.HMAX\n",
    "    true_fcast   = norm_s[3]*(capm.NO_OF_DAYTYPE-1)\n",
    "    \n",
    "    return[true_batt, true_enp, true_henergy, true_fcast]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "QFILENAME = NAME + '_' + str(seed) + \"_QTABLE_\" + str(QUANTIZATION_LEVEL) + \".npy\"\n",
    "Q_TABLE = np.load(QFILENAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1728x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x        = Q_TABLE.flatten()\n",
    "print(x.size)\n",
    "num_bins = QUANTIZATION_LEVEL\n",
    "fig = plt.figure(figsize=(24,10))\n",
    "n, bins, patches = plt.hist(x, num_bins, facecolor='green', alpha=1.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***MEASURING PERFORMANCE OF THE MODEL***\n",
      "YEAR: 2000\n",
      "Average Reward    :  1.455\n",
      "Battery Violations:  0\n"
     ]
    }
   ],
   "source": [
    "#TESTING\n",
    "print(\"***MEASURING PERFORMANCE OF THE MODEL***\")\n",
    "results = np.empty(4)\n",
    "LOCATION = 'tokyo'\n",
    "for YEAR in np.arange(2000,2001):\n",
    "    capm      = CAPM(LOCATION,YEAR,shuffle=False, trainmode=False) #instantiate the CAPM class\n",
    "    capm.eno  = ENO(LOCATION,YEAR, shuffle=False, day_balance=False) #instantiate the environment inside the CAPM class\n",
    "    capm.HMAX = capm.eno.SMAX #maximum power output of solar cell is set in CAPM object using the value in ENO object\n",
    "\n",
    "    s, r, day_end, year_end = capm.reset()\n",
    "    yr_test_record = np.empty(4)\n",
    "    while True:\n",
    "        # Get true values by denormalizing the state\n",
    "        true_batt,  true_enp,  true_henergy,  true_fcast  = denormalize(s)\n",
    "        # Get states\n",
    "        batt_state, enp_state, henergy_state, fcast_state = discretize(true_batt, true_enp, true_henergy, true_fcast)\n",
    "        # Choose action from Q_TABLE\n",
    "        a = Q_TABLE[batt_state, enp_state, henergy_state, fcast_state,:].argmax()\n",
    "        yr_test_record = np.vstack((yr_test_record, [s[0],s[2],r, a])) #record battery, henergy, reward and action\n",
    "        # Execute Action\n",
    "        s_, r, day_end, year_end = capm.step(a)\n",
    "        if year_end:\n",
    "            break\n",
    "        s = s_\n",
    "\n",
    "    yr_test_record = np.delete(yr_test_record, 0, 0) #remove the first row which is garbage\n",
    "    yr_test_reward_rec = yr_test_record[:,2]\n",
    "    yr_test_reward_rec = yr_test_reward_rec[::24] #annual average reward\n",
    "#     results = np.vstack((results, [int(YEAR), np.mean(yr_test_reward_rec), int(capm.violation_counter), int(capm.batt_violations)]))\n",
    "#     print(\"\\n\")\n",
    "    print(\"YEAR:\", YEAR)\n",
    "    print(\"Average Reward    : {:6.4}\".format(np.mean(yr_test_reward_rec)))\n",
    "    print(\"Battery Violations: \" , int(capm.batt_violations))\n",
    "\n",
    "# # ###########################################################################################\n",
    "# # ###########################################################################################\n",
    "#     #     Plot the reward and battery for the entire year run\n",
    "#     title = LOCATION.upper() + ',' + str(YEAR)\n",
    "#     NO_OF_DAYS = capm.eno.NO_OF_DAYS\n",
    "\n",
    "#     fig = plt.figure(figsize=(24,6))\n",
    "#     fig.suptitle(title, fontsize=15)\n",
    "    \n",
    "# #     ax1 = fig.add_subplot(211)\n",
    "# #     ax1.plot(yr_test_reward_rec)\n",
    "# #     ax1.set_title(\"\\n\\nYear Run Reward\")\n",
    "# #     ax1.set_ylim([-3,3])\n",
    "    \n",
    "#     ax2 = fig.add_subplot(111)\n",
    "#     ax2.plot(yr_test_record[:,0],'r')\n",
    "#     ax2.plot(np.ones_like(yr_test_record[:,0])*capm.BOPT/capm.BMAX, 'k--')\n",
    "#     ax2.plot(np.ones_like(yr_test_record[:,0])*capm.BLIM_LO/capm.BMAX, 'r:')\n",
    "#     ax2.plot(np.ones_like(yr_test_record[:,0])*capm.BLIM_HI/capm.BMAX, 'r:')\n",
    "#     ax2.plot(np.ones_like(yr_test_record[:,0])*(capm.BOPT+capm.ENP_MARGIN /2) /capm.BMAX, 'g:')\n",
    "#     ax2.plot(np.ones_like(yr_test_record[:,0])*(capm.BOPT-capm.ENP_MARGIN/2)/capm.BMAX, 'g:')\n",
    "#     ax2.set_title(\"\\n\\nYear Run Battery\")\n",
    "#     ax2.set_ylim([0,1])\n",
    "#     plt.sca(ax2)\n",
    "#     plt.xticks(np.arange(0, NO_OF_DAYS*24, 50*24),np.arange(0,NO_OF_DAYS,50))\n",
    "#     fig.tight_layout()\n",
    "#     plt.show()\n",
    "# # ###########################################################################################\n",
    "# # ###########################################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR                  = 1e-4          # learning rate\n",
    "EPSILON             = 1\n",
    "GAMMA               = 0.95           # reward discount\n",
    "NO_OF_ITERATIONS    = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration # 0\t\tYEAR: 2000\t\tAverage Reward:  1.455\t\tBattery Violations: 0\n",
      "Iteration # 1\t\tYEAR: 2000\t\tAverage Reward:  1.435\t\tBattery Violations: 0\n",
      "Iteration # 2\t\tYEAR: 2000\t\tAverage Reward:  1.410\t\tBattery Violations: 0\n",
      "Iteration # 3\t\tYEAR: 2000\t\tAverage Reward:  1.384\t\tBattery Violations: 0\n",
      "Iteration # 4\t\tYEAR: 2000\t\tAverage Reward:  1.248\t\tBattery Violations: 0\n",
      "Iteration # 5\t\tYEAR: 2000\t\tAverage Reward:  1.217\t\tBattery Violations: 0\n",
      "Iteration # 6\t\tYEAR: 2000\t\tAverage Reward:  1.209\t\tBattery Violations: 0\n",
      "Iteration # 7\t\tYEAR: 2000\t\tAverage Reward:  1.183\t\tBattery Violations: 0\n",
      "Iteration # 8\t\tYEAR: 2000\t\tAverage Reward:  1.194\t\tBattery Violations: 0\n",
      "Iteration # 9\t\tYEAR: 2000\t\tAverage Reward:  1.180\t\tBattery Violations: 0\n",
      "Iteration # 10\t\tYEAR: 2000\t\tAverage Reward:  1.151\t\tBattery Violations: 0\n",
      "Iteration # 11\t\tYEAR: 2000\t\tAverage Reward:  1.176\t\tBattery Violations: 0\n",
      "Iteration # 12\t\tYEAR: 2000\t\tAverage Reward:  1.156\t\tBattery Violations: 0\n",
      "Iteration # 13\t\tYEAR: 2000\t\tAverage Reward:  1.169\t\tBattery Violations: 0\n",
      "Iteration # 14\t\tYEAR: 2000\t\tAverage Reward:  1.152\t\tBattery Violations: 0\n",
      "Iteration # 15\t\tYEAR: 2000\t\tAverage Reward:  1.179\t\tBattery Violations: 0\n",
      "Iteration # 16\t\tYEAR: 2000\t\tAverage Reward:  1.154\t\tBattery Violations: 0\n",
      "Iteration # 17\t\tYEAR: 2000\t\tAverage Reward:  1.178\t\tBattery Violations: 0\n",
      "Iteration # 18\t\tYEAR: 2000\t\tAverage Reward:  1.174\t\tBattery Violations: 0\n",
      "Iteration # 19\t\tYEAR: 2000\t\tAverage Reward:  1.158\t\tBattery Violations: 0\n",
      "Iteration # 20\t\tYEAR: 2000\t\tAverage Reward:  1.168\t\tBattery Violations: 0\n",
      "Iteration # 21\t\tYEAR: 2000\t\tAverage Reward:  1.170\t\tBattery Violations: 0\n",
      "Iteration # 22\t\tYEAR: 2000\t\tAverage Reward:  1.198\t\tBattery Violations: 0\n",
      "Iteration # 23\t\tYEAR: 2000\t\tAverage Reward:  1.170\t\tBattery Violations: 0\n",
      "Iteration # 24\t\tYEAR: 2000\t\tAverage Reward:  1.168\t\tBattery Violations: 0\n",
      "Iteration # 25\t\tYEAR: 2000\t\tAverage Reward:  1.126\t\tBattery Violations: 0\n",
      "Iteration # 26\t\tYEAR: 2000\t\tAverage Reward:  1.117\t\tBattery Violations: 0\n",
      "Iteration # 27\t\tYEAR: 2000\t\tAverage Reward:  1.106\t\tBattery Violations: 0\n",
      "Iteration # 28\t\tYEAR: 2000\t\tAverage Reward:  1.122\t\tBattery Violations: 0\n",
      "Iteration # 29\t\tYEAR: 2000\t\tAverage Reward:  1.097\t\tBattery Violations: 0\n",
      "Iteration # 30\t\tYEAR: 2000\t\tAverage Reward:  1.109\t\tBattery Violations: 0\n",
      "Iteration # 31\t\tYEAR: 2000\t\tAverage Reward:  1.117\t\tBattery Violations: 0\n",
      "Iteration # 32\t\tYEAR: 2000\t\tAverage Reward:  1.095\t\tBattery Violations: 0\n",
      "Iteration # 33\t\tYEAR: 2000\t\tAverage Reward:  1.120\t\tBattery Violations: 0\n",
      "Iteration # 34\t\tYEAR: 2000\t\tAverage Reward:  1.094\t\tBattery Violations: 0\n",
      "Iteration # 35\t\tYEAR: 2000\t\tAverage Reward:  1.076\t\tBattery Violations: 0\n",
      "Iteration # 36\t\tYEAR: 2000\t\tAverage Reward:  1.076\t\tBattery Violations: 0\n",
      "Iteration # 37\t\tYEAR: 2000\t\tAverage Reward:  1.093\t\tBattery Violations: 0\n",
      "Iteration # 38\t\tYEAR: 2000\t\tAverage Reward:  1.080\t\tBattery Violations: 0\n",
      "Iteration # 39\t\tYEAR: 2000\t\tAverage Reward:  1.089\t\tBattery Violations: 0\n",
      "Iteration # 40\t\tYEAR: 2000\t\tAverage Reward:  1.075\t\tBattery Violations: 0\n",
      "Iteration # 41\t\tYEAR: 2000\t\tAverage Reward:  1.068\t\tBattery Violations: 0\n",
      "Iteration # 42\t\tYEAR: 2000\t\tAverage Reward:  1.070\t\tBattery Violations: 0\n",
      "Iteration # 43\t\tYEAR: 2000\t\tAverage Reward:  1.065\t\tBattery Violations: 0\n",
      "Iteration # 44\t\tYEAR: 2000\t\tAverage Reward:  1.078\t\tBattery Violations: 0\n",
      "Iteration # 45\t\tYEAR: 2000\t\tAverage Reward:  1.069\t\tBattery Violations: 0\n",
      "Iteration # 46\t\tYEAR: 2000\t\tAverage Reward:  1.095\t\tBattery Violations: 0\n",
      "Iteration # 47\t\tYEAR: 2000\t\tAverage Reward:  1.028\t\tBattery Violations: 0\n",
      "Iteration # 48\t\tYEAR: 2000\t\tAverage Reward:  1.070\t\tBattery Violations: 0\n",
      "Iteration # 49\t\tYEAR: 2000\t\tAverage Reward:  1.078\t\tBattery Violations: 0\n",
      "Iteration # 50\t\tYEAR: 2000\t\tAverage Reward:  1.033\t\tBattery Violations: 0\n",
      "Iteration # 51\t\tYEAR: 2000\t\tAverage Reward:  1.033\t\tBattery Violations: 0\n",
      "Iteration # 52\t\tYEAR: 2000\t\tAverage Reward:  1.018\t\tBattery Violations: 0\n",
      "Iteration # 53\t\tYEAR: 2000\t\tAverage Reward:  1.005\t\tBattery Violations: 0\n",
      "Iteration # 54\t\tYEAR: 2000\t\tAverage Reward:  1.061\t\tBattery Violations: 0\n",
      "Iteration # 55\t\tYEAR: 2000\t\tAverage Reward:  1.009\t\tBattery Violations: 0\n",
      "Iteration # 56\t\tYEAR: 2000\t\tAverage Reward:  1.004\t\tBattery Violations: 0\n",
      "Iteration # 57\t\tYEAR: 2000\t\tAverage Reward:  1.019\t\tBattery Violations: 0\n",
      "Iteration # 58\t\tYEAR: 2000\t\tAverage Reward:  1.006\t\tBattery Violations: 0\n",
      "Iteration # 59\t\tYEAR: 2000\t\tAverage Reward:  0.989\t\tBattery Violations: 0\n",
      "Iteration # 60\t\tYEAR: 2000\t\tAverage Reward:  0.988\t\tBattery Violations: 0\n"
     ]
    }
   ],
   "source": [
    "# experience_rec = np.empty(N_STATES * 2 + 2) #record all the transitions during training\n",
    "\n",
    "results = np.empty(4)\n",
    "for iteration in range(NO_OF_ITERATIONS):\n",
    "    LOCATION    = 'tokyo'#random.choice(['tokyo','wakkanai','minamidaito'])\n",
    "    YEAR        = 2000#random.choice(np.arange(2000,2010))\n",
    "    capm        = CAPM(LOCATION,YEAR,shuffle=False, trainmode=False) #instantiate the CAPM class\n",
    "    capm.eno    = ENO(LOCATION,YEAR, shuffle=False, day_balance=False) #instantiate the environment inside the CAPM class\n",
    "    capm.HMAX   = capm.eno.SMAX #maximum power output of solar cell is set in CAPM object using the value in ENO object\n",
    "\n",
    "    s, r, day_end, year_end = capm.reset()\n",
    "    yr_test_record = np.empty(4)\n",
    "\n",
    "    while True:\n",
    "        # Get true values by denormalizing the state\n",
    "        true_batt,  true_enp,  true_henergy,  true_fcast  = denormalize(s)\n",
    "        # Get states\n",
    "        batt_state, enp_state, henergy_state, fcast_state = discretize(true_batt, true_enp, true_henergy, true_fcast)\n",
    "        \n",
    "        # Choose action from Q_TABLE using e-greedy policy\n",
    "        a = Q_TABLE[batt_state, enp_state, henergy_state, fcast_state,:].argmax()\n",
    "        if np.random.uniform() > EPSILON:   # greedy\n",
    "            a += np.random.randint(-3, 3)\n",
    "        a = int(np.clip(a, 0, N_ACTIONS-1))\n",
    "        \n",
    "        yr_test_record = np.vstack((yr_test_record, [s[0],s[2],r, a])) #record battery, henergy, reward and action\n",
    "\n",
    "        # Execute Action\n",
    "        s_, r, day_end, year_end = capm.step(a)\n",
    "        # Get next_state\n",
    "        next_batt,  next_enp,  next_henergy,  next_fcast  = denormalize(s_)\n",
    "        next_batt_state, next_enp_state, next_henergy_state, next_fcast_state = discretize(next_batt,  next_enp,  next_henergy,  next_fcast)\n",
    "        \n",
    "        #Remember experience\n",
    "        temp_transitions   = np.hstack((stdize(s), [a, r], stdize(s_)))\n",
    "#         experience_rec     = np.vstack((experience_rec, temp_transitions))\n",
    "        \n",
    "        #Update Q-table\n",
    "        Q_TABLE[batt_state, enp_state, henergy_state, fcast_state,a] = Q_TABLE[batt_state, enp_state, henergy_state, fcast_state,a] + \\\n",
    "                                                                       LR * (r + GAMMA * Q_TABLE[next_batt_state, next_enp_state, next_henergy_state, next_fcast_state,:].max() - \\\n",
    "                                                                            Q_TABLE[batt_state, enp_state, henergy_state, fcast_state,a])\n",
    "\n",
    "        if year_end:\n",
    "            break\n",
    "        s = s_\n",
    "        \n",
    "    yr_test_record  = np.delete(yr_test_record,  0, 0) #remove the first row which is garbage\n",
    "    yr_test_reward_rec = yr_test_record[:,2]\n",
    "    yr_test_reward_rec = yr_test_reward_rec[::24] #annual average reward\n",
    "#     print(\"\\n\")\n",
    "    print(\"Iteration #\", iteration, end=\"\\t\\t\")\n",
    "    print(\"YEAR:\", YEAR, end=\"\\t\\t\")\n",
    "    print(\"Average Reward: {: 06.3f}\".format(np.mean(yr_test_reward_rec)), end=\"\\t\\t\")\n",
    "    print(\"Battery Violations:\" , int(capm.batt_violations))\n",
    "    results = np.vstack((results, [int(YEAR), np.mean(yr_test_reward_rec), int(capm.violation_counter), int(capm.batt_violations)]))\n",
    "\n",
    "#     # ###########################################################################################\n",
    "#     # ###########################################################################################\n",
    "#     #     Plot the reward and battery for the entire year run\n",
    "#     title = LOCATION.upper() + ',' + str(YEAR)\n",
    "#     NO_OF_DAYS = capm.eno.NO_OF_DAYS\n",
    "\n",
    "#     fig = plt.figure(figsize=(24,3))\n",
    "#     fig.suptitle(title, fontsize=15)\n",
    "\n",
    "#     #     ax1 = fig.add_subplot(211)\n",
    "#     #     ax1.plot(yr_test_reward_rec)\n",
    "#     #     ax1.set_title(\"\\n\\nYear Run Reward\")\n",
    "#     #     ax1.set_ylim([-3,3])\n",
    "\n",
    "#     ax2 = fig.add_subplot(111)\n",
    "#     ax2.plot(yr_test_record[:,0],'r')\n",
    "#     ax2.plot(np.ones_like(yr_test_record[:,0])*capm.BOPT/capm.BMAX, 'k--')\n",
    "#     ax2.plot(np.ones_like(yr_test_record[:,0])*capm.BLIM_LO/capm.BMAX, 'r:')\n",
    "#     ax2.plot(np.ones_like(yr_test_record[:,0])*capm.BLIM_HI/capm.BMAX, 'r:')\n",
    "#     ax2.plot(np.ones_like(yr_test_record[:,0])*(capm.BOPT+capm.ENP_MARGIN /2) /capm.BMAX, 'g:')\n",
    "#     ax2.plot(np.ones_like(yr_test_record[:,0])*(capm.BOPT-capm.ENP_MARGIN/2)/capm.BMAX, 'g:')\n",
    "#     ax2.set_title(\"\\n\\nYear Run Battery\")\n",
    "#     ax2.set_ylim([0,1])\n",
    "#     plt.sca(ax2)\n",
    "#     plt.xticks(np.arange(0, NO_OF_DAYS*24, 50*24),np.arange(0,NO_OF_DAYS,50))\n",
    "#     fig.tight_layout()\n",
    "#     plt.show()\n",
    "#     # ###########################################################################################\n",
    "#     # ###########################################################################################\n",
    "# experience_rec = np.delete(experience_rec, 0, 0)\n",
    "results = np.delete(results, 0, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(results[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
